{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The feature engineering was redone starting from the original work and with extra work by us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#updates:\n",
    "#applied imputation into numerical and categorical data to improve the score by 0.327, now 0.9194\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import stats\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "\n",
    "import gc\n",
    "import os \n",
    "\n",
    "#print where those datasets are located \n",
    "from sklearn.preprocessing import minmax_scale\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "#df_trans = pd.read_csv('train_transaction.csv')\n",
    "df_trans = pd.read_csv('train_transaction.csv',index_col='TransactionID')\n",
    "df_test_trans = pd.read_csv('test_transaction.csv',index_col='TransactionID')\n",
    "\n",
    "#record index of test datasets\n",
    "test_trans_id = df_test_trans.index\n",
    "\n",
    "#df_id = pd.read_csv('train_identity.csv')\n",
    "df_id = pd.read_csv('train_identity.csv',index_col='TransactionID')\n",
    "df_test_id = pd.read_csv('test_identity.csv',index_col='TransactionID')\n",
    "\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col='TransactionID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_split(dataframe):\n",
    "    \n",
    "    #expand = split and expand to seperate column\n",
    "    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n",
    "    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n",
    "\n",
    "    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n",
    "    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n",
    "\n",
    "    dataframe['id_34'] = dataframe['id_34'].str.split(':', expand=True)[1]\n",
    "    dataframe['id_23'] = dataframe['id_23'].str.split(':', expand=True)[1]\n",
    "    \n",
    "    #very specifically group device brands to help making decision\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n",
    "\n",
    "    #make the device name that are less than 200 to be other\n",
    "    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "    \n",
    "    #new column to record that this device has id???\n",
    "    dataframe['had_id'] = 1\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = id_split(df_id)\n",
    "df_test_id = id_split(df_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5ab30789dc00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_id' is not defined"
     ]
    }
   ],
   "source": [
    "df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##do not need to include right_index\n",
    "df_train = df_trans.merge(df_id, how='left', left_index=True,  on='TransactionID')\n",
    "df_test = df_test_trans.merge(df_test_id, how='left', left_index=True, on='TransactionID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>id_10</th>\n",
       "      <th>id_11</th>\n",
       "      <th>id_12</th>\n",
       "      <th>id_13</th>\n",
       "      <th>id_14</th>\n",
       "      <th>id_15</th>\n",
       "      <th>id_16</th>\n",
       "      <th>id_17</th>\n",
       "      <th>...</th>\n",
       "      <th>C_sum</th>\n",
       "      <th>M1_null</th>\n",
       "      <th>M4_null</th>\n",
       "      <th>id14_null</th>\n",
       "      <th>id01_null</th>\n",
       "      <th>id07_null</th>\n",
       "      <th>d12_null</th>\n",
       "      <th>devicename_null</th>\n",
       "      <th>id_null</th>\n",
       "      <th>tot_na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2987000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-480.0</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id_08  id_09  id_10  id_11     id_12  id_13  id_14 id_15  \\\n",
       "TransactionID                                                             \n",
       "2987000          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "2987001          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "2987002          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "2987003          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "2987004          NaN    NaN    NaN  100.0  NotFound    NaN -480.0   New   \n",
       "...              ...    ...    ...    ...       ...    ...    ...   ...   \n",
       "3577535          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "3577536          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "3577537          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "3577538          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "3577539          NaN    NaN    NaN    NaN       NaN    NaN    NaN   NaN   \n",
       "\n",
       "                  id_16  id_17  ...  C_sum  M1_null  M4_null  id14_null  \\\n",
       "TransactionID                   ...                                       \n",
       "2987000             NaN    NaN  ...      8        0        0          1   \n",
       "2987001             NaN    NaN  ...      6        1        0          1   \n",
       "2987002             NaN    NaN  ...      7        0        0          1   \n",
       "2987003             NaN    NaN  ...     39        1        0          1   \n",
       "2987004        NotFound  166.0  ...      8        1        1          0   \n",
       "...                 ...    ...  ...    ...      ...      ...        ...   \n",
       "3577535             NaN    NaN  ...     12        0        0          1   \n",
       "3577536             NaN    NaN  ...      7        0        0          1   \n",
       "3577537             NaN    NaN  ...      8        0        1          1   \n",
       "3577538             NaN    NaN  ...     15        0        0          1   \n",
       "3577539             NaN    NaN  ...     10        0        1          1   \n",
       "\n",
       "               id01_null id07_null  d12_null  devicename_null  id_null tot_na  \n",
       "TransactionID                                                                  \n",
       "2987000                1         1         1                1      NaN    -12  \n",
       "2987001                1         1         1                1      NaN    -16  \n",
       "2987002                1         1         1                1      NaN    -35  \n",
       "2987003                1         1         1                1      NaN    -19  \n",
       "2987004                0         1         1                0     17.0   -119  \n",
       "...                  ...       ...       ...              ...      ...    ...  \n",
       "3577535                1         1         1                1      NaN    -16  \n",
       "3577536                1         1         1                1      NaN    -34  \n",
       "3577537                1         1         1                1      NaN    -29  \n",
       "3577538                1         1         1                1      NaN    -35  \n",
       "3577539                1         1         1                1      NaN    -34  \n",
       "\n",
       "[590540 rows x 52 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[:,400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#C sum feature\n",
    "df_train[\"C_sum\"] = df_train.loc[:,'C1':'C14'].sum(axis = 1).astype(np.int8)\n",
    "df_test[\"C_sum\"] = df_test.loc[:,'C1':'C14'].sum(axis = 1).astype(np.int8)\n",
    "\n",
    "    \n",
    "##isnull feature: some features have missing values all together so one will be put here.\n",
    "#M1, M4, id_14,id_01, id_07, \n",
    "\n",
    "##M1,m4\n",
    "\n",
    "df_train['M1_null'] = df_train.loc[:,'M1'].isna().astype(np.int8)\n",
    "df_train['M4_null'] = df_train.loc[:,'M4'].isna().astype(np.int8)\n",
    "df_test['M1_null'] = df_test.loc[:,'M1'].isna().astype(np.int8)\n",
    "df_test['M4_null'] = df_test.loc[:,'M4'].isna().astype(np.int8)\n",
    "\n",
    "df_train['id14_null'] = df_train.loc[:,'id_14'].isna().astype(np.int8)\n",
    "df_train['id01_null'] = df_train.loc[:,'id_01'].isna().astype(np.int8)\n",
    "df_train['id07_null'] = df_train.loc[:,'id_07'].isna().astype(np.int8)\n",
    "df_train['d12_null'] = df_train.loc[:,'D12'].isna().astype(np.int8)\n",
    "df_train['devicename_null'] = df_train.loc[:,'device_name'].isna().astype(np.int8)\n",
    "df_test['id14_null'] = df_test.loc[:,'id_14'].isna().astype(np.int8)\n",
    "df_test['id01_null'] = df_test.loc[:,'id_01'].isna().astype(np.int8)\n",
    "df_test['id07_null'] = df_test.loc[:,'id_07'].isna().astype(np.int8)\n",
    "df_test['d12_null'] = df_test.loc[:,'D12'].isna().astype(np.int8)\n",
    "df_test['devicename_null'] = df_test.loc[:,'device_name'].isna().astype(np.int8)\n",
    "\n",
    "##ids \n",
    "df_train['id_null'] = df_id.loc[:,\"id_01\":\"id_38\"].isna().sum(axis=1).astype(np.int8)\n",
    "df_test['id_null'] = df_test_id.loc[:,\"id_01\":\"id_38\"].isna().sum(axis=1).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000     NaN\n",
       "2987001     NaN\n",
       "2987002     NaN\n",
       "2987003     NaN\n",
       "2987004    17.0\n",
       "           ... \n",
       "3577535     NaN\n",
       "3577536     NaN\n",
       "3577537     NaN\n",
       "3577538     NaN\n",
       "3577539     NaN\n",
       "Name: id_null, Length: 590540, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['id_null']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               isFraud  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
      "TransactionID                                                                   \n",
      "2987000              0          86400            68.5         W  13926    NaN   \n",
      "2987001              0          86401            29.0         W   2755  404.0   \n",
      "2987002              0          86469            59.0         W   4663  490.0   \n",
      "2987003              0          86499            50.0         W  18132  567.0   \n",
      "2987004              0          86506            50.0         H   4497  514.0   \n",
      "\n",
      "               card3       card4  card5   card6  ...  C_sum  M1_null  M4_null  \\\n",
      "TransactionID                                    ...                            \n",
      "2987000        150.0    discover  142.0  credit  ...      8        0        0   \n",
      "2987001        150.0  mastercard  102.0  credit  ...      6        1        0   \n",
      "2987002        150.0        visa  166.0   debit  ...      7        0        0   \n",
      "2987003        150.0  mastercard  117.0   debit  ...     39        1        0   \n",
      "2987004        150.0  mastercard  102.0  credit  ...      8        1        1   \n",
      "\n",
      "               id14_null id01_null id07_null  d12_null  devicename_null  \\\n",
      "TransactionID                                                             \n",
      "2987000                1         1         1         1                1   \n",
      "2987001                1         1         1         1                1   \n",
      "2987002                1         1         1         1                1   \n",
      "2987003                1         1         1         1                1   \n",
      "2987004                0         0         1         1                0   \n",
      "\n",
      "               id_null  tot_na  \n",
      "TransactionID                   \n",
      "2987000            NaN     -12  \n",
      "2987001            NaN     -16  \n",
      "2987002            NaN     -35  \n",
      "2987003            NaN     -19  \n",
      "2987004           17.0    -119  \n",
      "\n",
      "[5 rows x 452 columns]\n",
      "               TransactionDT  TransactionAmt ProductCD  card1  card2  card3  \\\n",
      "TransactionID                                                                 \n",
      "3663549             18403224           31.95         W  10409  111.0  150.0   \n",
      "3663550             18403263           49.00         W   4272  111.0  150.0   \n",
      "3663551             18403310          171.00         W   4476  574.0  150.0   \n",
      "3663552             18403310          284.95         W  10989  360.0  150.0   \n",
      "3663553             18403317           67.95         W  18018  452.0  150.0   \n",
      "\n",
      "                    card4  card5  card6  addr1  ...  C_sum  M1_null  M4_null  \\\n",
      "TransactionID                                   ...                            \n",
      "3663549              visa  226.0  debit  170.0  ...   -104        0        1   \n",
      "3663550              visa  226.0  debit  299.0  ...     24        0        0   \n",
      "3663551              visa  226.0  debit  472.0  ...     39        0        0   \n",
      "3663552              visa  166.0  debit  205.0  ...     24        0        1   \n",
      "3663553        mastercard  117.0  debit  264.0  ...     50        0        1   \n",
      "\n",
      "              id14_null id01_null  id07_null  d12_null  devicename_null  \\\n",
      "TransactionID                                                             \n",
      "3663549               1         1          1         1                1   \n",
      "3663550               1         1          1         1                1   \n",
      "3663551               1         1          1         1                1   \n",
      "3663552               1         1          1         1                1   \n",
      "3663553               1         1          1         1                1   \n",
      "\n",
      "               id_null  tot_na  \n",
      "TransactionID                   \n",
      "3663549            NaN     -36  \n",
      "3663550            NaN     -34  \n",
      "3663551            NaN     -38  \n",
      "3663552            NaN     -33  \n",
      "3663553            NaN     -36  \n",
      "\n",
      "[5 rows x 451 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#add total na for train and test data. \n",
    "df_train['tot_na'] = df_train.isna().sum(axis=1).astype(np.int8) \n",
    "df_test['tot_na'] = df_test.isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "\n",
    "\n",
    "# y_train = df_train['isFraud'].copy()\n",
    "del df_trans, df_id, df_test_trans, df_test_id\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1600'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[3577531,\"screen_height\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/davidcairuz/feature-engineering-lightgbm#\n",
    "#removed V300 feature\n",
    "#https://www.kaggle.com/nroman/recursive-feature-elimination \n",
    "useful_features = ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1',\n",
    "                   'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13',\n",
    "                   'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M2', 'M3',\n",
    "                   'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V17',\n",
    "                   'V19', 'V20', 'V29', 'V30', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V40', 'V44', 'V45', 'V46', 'V47', 'V48',\n",
    "                   'V49', 'V51', 'V52', 'V53', 'V54', 'V56', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V69', 'V70', 'V71',\n",
    "                   'V72', 'V73', 'V74', 'V75', 'V76', 'V78', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V87', 'V90', 'V91', 'V92',\n",
    "                   'V93', 'V94', 'V95', 'V96', 'V97', 'V99', 'V100', 'V126', 'V127', 'V128', 'V130', 'V131', 'V138', 'V139', 'V140',\n",
    "                   'V143', 'V145', 'V146', 'V147', 'V149', 'V150', 'V151', 'V152', 'V154', 'V156', 'V158', 'V159', 'V160', 'V161',\n",
    "                   'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V169', 'V170', 'V171', 'V172', 'V173', 'V175', 'V176', 'V177',\n",
    "                   'V178', 'V180', 'V182', 'V184', 'V187', 'V188', 'V189', 'V195', 'V197', 'V200', 'V201', 'V202', 'V203', 'V204',\n",
    "                   'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V219', 'V220',\n",
    "                   'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V231', 'V233', 'V234', 'V238', 'V239',\n",
    "                   'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V249', 'V251', 'V253', 'V256', 'V257', 'V258', 'V259', 'V261',\n",
    "                   'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276',\n",
    "                   'V277', 'V278', 'V279', 'V280', 'V282', 'V283', 'V285', 'V287', 'V288', 'V289', 'V291', 'V292', 'V294','id_01', 'id_02', 'id_03', 'id_05', 'id_06', 'id_09',\n",
    "                   'id_11', 'id_12', 'id_13', 'id_14', 'id_17', 'id_19', 'id_20', 'id_30', 'id_31', 'id_33',\n",
    "                    'id_38', 'DeviceType', 'DeviceInfo', 'device_name', 'device_version', 'OS_id_30', 'version_id_30',\n",
    "                   'browser_id_31', 'version_id_31', 'screen_width', 'screen_height', 'had_id','tot_na','id_null','M1_null','M4_null','id01_null','id07_null','id14_null','d12_null','devicename_null']\n",
    "print(len(useful_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in df_train.columns if col not in useful_features]\n",
    "cols_to_drop.remove('isFraud')\n",
    "cols_to_drop.remove('TransactionDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(cols_to_drop, axis=1)\n",
    "df_test = df_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added card6 - debit credit\n",
    "columns_a = ['TransactionAmt', 'D15','dist1']\n",
    "columns_b = ['card1', 'card4', 'addr1','card6']\n",
    "\n",
    "for col_a in columns_a:\n",
    "    for col_b in columns_b:\n",
    "        for df in [df_train, df_test]:\n",
    "            df[f'{col_a}_to_mean_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('mean')\n",
    "            df[f'{col_a}_to_std_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature - log of transaction amount.\n",
    "df_train['TransactionAmt_Log'] = np.log(df_train['TransactionAmt'])\n",
    "df_test['TransactionAmt_Log'] = np.log(df_test['TransactionAmt'])\n",
    "\n",
    "# New feature - decimal part of the transaction amount.\n",
    "df_train['TransactionAmt_decimal'] = ((df_train['TransactionAmt'] - df_train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "df_test['TransactionAmt_decimal'] = ((df_test['TransactionAmt'] - df_test['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "\n",
    "# New feature - day of week in which a transaction happened.\n",
    "df_train['Transaction_day_of_week'] = np.floor((df_train['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "df_test['Transaction_day_of_week'] = np.floor((df_test['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "\n",
    "# New feature - hour of the day in which a transaction happened.\n",
    "df_train['Transaction_hour'] = np.floor(df_train['TransactionDT'] / 3600) % 24\n",
    "df_test['Transaction_hour'] = np.floor(df_test['TransactionDT'] / 3600) % 24\n",
    "\n",
    "# Some arbitrary features interaction\n",
    "for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    df_train[feature] = df_train[f1].astype(str) + '_' + df_train[f2].astype(str)\n",
    "    df_test[feature] = df_test[f1].astype(str) + '_' + df_test[f2].astype(str)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list(df_train[feature].astype(str).values) + list(df_test[feature].astype(str).values))\n",
    "    df_train[feature] = le.transform(list(df_train[feature].astype(str).values))\n",
    "    df_test[feature] = le.transform(list(df_test[feature].astype(str).values))\n",
    "\n",
    "# Encoding - count encoding for both df_train and df_test\n",
    "for feature in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6']:\n",
    "    df_train[feature + '_count_full'] = df_train[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    df_test[feature + '_count_full'] = df_test[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# Encoding - count encoding separately for df_train and df_test\n",
    "for feature in ['id_01', 'id_31', 'id_33']:\n",
    "    df_train[feature + '_count_dist'] = df_train[feature].map(df_train[feature].value_counts(dropna=False))\n",
    "    df_test[feature + '_count_dist'] = df_test[feature].map(df_test[feature].value_counts(dropna=False))\n",
    "    \n",
    "#target encoding\n",
    "for col in ['addr1','tot_na','id_null','Transaction_hour']:\n",
    "    temp_dict = df_train.groupby([col])['isFraud'].agg(['mean']).reset_index().rename(\n",
    "                                                        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    df_train[col+'_target_mean'] = df_train[col].map(temp_dict)\n",
    "    df_test[col+'_target_mean']  = df_test[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100499\n",
    "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n",
    "          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n",
    "          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n",
    "          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n",
    "          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n",
    "          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n",
    "          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n",
    "          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n",
    "          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n",
    "          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n",
    "          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n",
    "          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n",
    "          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n",
    "          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n",
    "          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n",
    "          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n",
    "          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n",
    "          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n",
    "          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n",
    "\n",
    "us_emails = ['gmail', 'net', 'edu']\n",
    "\n",
    "for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "    df_train[c + '_bin'] = df_train[c].map(emails)\n",
    "    df_test[c + '_bin'] = df_test[c].map(emails)\n",
    "    \n",
    "    df_train[c + '_suffix'] = df_train[c].map(lambda x: str(x).split('.')[-1])\n",
    "    df_test[c + '_suffix'] = df_test[c].map(lambda x: str(x).split('.')[-1])\n",
    "    \n",
    "    df_train[c + '_suffix'] = df_train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "    df_test[c + '_suffix'] = df_test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more arbitrary features interaction\n",
    "for feature in ['id_01__P_emaildomain_bin', 'DeviceInfo__P_emaildomain_suffix']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    df_train[feature] = df_train[f1].astype(str) + '_' + df_train[f2].astype(str)\n",
    "    df_test[feature] = df_test[f1].astype(str) + '_' + df_test[f2].astype(str)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list(df_train[feature].astype(str).values) + list(df_test[feature].astype(str).values))\n",
    "    df_train[feature] = le.transform(list(df_train[feature].astype(str).values))\n",
    "    df_test[feature] = le.transform(list(df_test[feature].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding the rest \n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n",
    "        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
    "        df_test[col] = le.transform(list(df_test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#why sort ??\n",
    "X_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\n",
    "y_train = df_train.sort_values('TransactionDT')['isFraud']\n",
    "\n",
    "X_test = df_test.drop(['TransactionDT'], axis=1)\n",
    "\n",
    "del df_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 413.38 Mb (71.5% reduction)\n",
      "Mem. usage decreased to 360.48 Mb (71.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "##do final step \n",
    "\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "##Deal with missing data\n",
    "\n",
    "X_train = X_train.fillna(-999)\n",
    "X_test = X_test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "##The following will carry out automated parameters optimisation for mainly accuray and overfitting related parameters based on Bayesian optimisation\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    missing=-999,\n",
    "    random_state=2019,\n",
    "    tree_method='hist'  # THE MAGICAL PARAMETER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data is predicted!!\n",
      "8480\n",
      "[0.00150777 0.00126542 0.00049773 ... 0.00784779 0.00940916 0.00525575]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#using data, ntree_limit to be nonzero\n",
    "y_pred= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Test data is predicted!!\")\n",
    "\n",
    "# Count how many fraud deteced/should be around 5900\n",
    "print(sum(y_pred > 0.5))\n",
    "print(y_pred)\n",
    "# submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20788"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub = pd.DataFrame(columns=['TransactionID','isFraud'])\n",
    "sub['TransactionID'] = test_trans_id\n",
    "sub['isFraud'] = y_pred\n",
    "sub\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sub.to_csv(\"submission44th-updated.csv\",index=False)\n",
    "\n",
    "sum(y_pred>0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
