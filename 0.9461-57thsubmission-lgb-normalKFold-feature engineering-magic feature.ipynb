{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The feature engineering was redone starting from the original work and with extra work by us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#updates:\n",
    "# added magic feature - boost the AUC by 0.0003\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import stats\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "# General imports\n",
    "\n",
    "import os, sys, gc, warnings, random, datetime, math\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "\n",
    "import gc\n",
    "import os \n",
    "\n",
    "#print where those datasets are located \n",
    "from sklearn.preprocessing import minmax_scale\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "#df_trans = pd.read_csv('train_transaction.csv')\n",
    "df_trans = pd.read_csv('train_transaction.csv',index_col='TransactionID')\n",
    "df_test_trans = pd.read_csv('test_transaction.csv',index_col='TransactionID')\n",
    "\n",
    "#record index of test datasets\n",
    "test_trans_id = df_test_trans.index\n",
    "\n",
    "#df_id = pd.read_csv('train_identity.csv')\n",
    "df_id = pd.read_csv('train_identity.csv',index_col='TransactionID')\n",
    "df_test_id = pd.read_csv('test_identity.csv',index_col='TransactionID')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col='TransactionID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_id = pd.read_csv('train_identity.csv')\n",
    "df_id = pd.read_csv('train_identity.csv',index_col='TransactionID')\n",
    "df_test_id = pd.read_csv('test_identity.csv',index_col='TransactionID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_split(dataframe):\n",
    "    \n",
    "    #expand = split and expand to seperate column\n",
    "    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n",
    "    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n",
    "\n",
    "    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n",
    "    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n",
    "\n",
    "    dataframe['id_34'] = dataframe['id_34'].str.split(':', expand=True)[1]\n",
    "    dataframe['id_23'] = dataframe['id_23'].str.split(':', expand=True)[1]\n",
    "    \n",
    "    #very specifically group device brands to help making decision\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n",
    "\n",
    "    #make the device name that are less than 200 to be other\n",
    "    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "    \n",
    "    #new column to record that this device has id???\n",
    "    dataframe['had_id'] = 1\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987004    0\n",
       "2987008    0\n",
       "2987016    0\n",
       "2987017    0\n",
       "2987022    0\n",
       "          ..\n",
       "3577465    0\n",
       "3577495    0\n",
       "3577506    0\n",
       "3577526    1\n",
       "3577531    0\n",
       "Name: isFraud, Length: 72668, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans[df_trans['V326']==0]['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#C sum feature\n",
    "df_trans[\"C_sum\"] = df_trans.loc[:,'C1':'C14'].sum(axis = 1).astype(np.int8)\n",
    "df_test_trans[\"C_sum\"] = df_test_trans.loc[:,'C1':'C14'].sum(axis = 1).astype(np.int8)\n",
    "\n",
    "    \n",
    "##D1 - D15\n",
    "df_trans['D_na'] =df_trans.loc[:,'D1':'D14'].isna().sum(axis=1).astype(np.int8)\n",
    "df_test_trans['D_na'] =df_test_trans.loc[:,'D1':'D14'].isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "    \n",
    "##M1-9\n",
    "i_cols = ['M1','M2','M3','M5','M6','M7','M8','M9']\n",
    "\n",
    "df_trans['M_na'] = df_trans[i_cols].isna().sum(axis=1).astype(np.int8)\n",
    "df_test_trans['M_na'] = df_test_trans[i_cols].isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "\n",
    "    \n",
    "##V_ features\n",
    "df_trans['V_na'] =df_trans.loc[:,\"V1\":\"V339\"].isna().sum(axis=1).astype(np.int8)\n",
    "df_test_trans['V_na'] =df_test_trans.loc[:,\"V1\":\"V339\"].isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "##ids \n",
    "df_id['id_na'] = df_id.loc[:,\"id_01\":\"id_38\"].isna().sum(axis=1).astype(np.int8)\n",
    "df_test_id['id_na'] = df_test_id.loc[:,\"id_01\":\"id_38\"].isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = id_split(df_id)\n",
    "df_test_id = id_split(df_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               isFraud  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
      "TransactionID                                                                   \n",
      "2987000              0          86400            68.5         W  13926    NaN   \n",
      "2987001              0          86401            29.0         W   2755  404.0   \n",
      "2987002              0          86469            59.0         W   4663  490.0   \n",
      "2987003              0          86499            50.0         W  18132  567.0   \n",
      "2987004              0          86506            50.0         H   4497  514.0   \n",
      "\n",
      "               card3       card4  card5   card6  ...  device_name  \\\n",
      "TransactionID                                    ...                \n",
      "2987000        150.0    discover  142.0  credit  ...          NaN   \n",
      "2987001        150.0  mastercard  102.0  credit  ...          NaN   \n",
      "2987002        150.0        visa  166.0   debit  ...          NaN   \n",
      "2987003        150.0  mastercard  117.0   debit  ...          NaN   \n",
      "2987004        150.0  mastercard  102.0  credit  ...      Samsung   \n",
      "\n",
      "               device_version  OS_id_30  version_id_30 browser_id_31  \\\n",
      "TransactionID                                                          \n",
      "2987000                   NaN       NaN            NaN           NaN   \n",
      "2987001                   NaN       NaN            NaN           NaN   \n",
      "2987002                   NaN       NaN            NaN           NaN   \n",
      "2987003                   NaN       NaN            NaN           NaN   \n",
      "2987004                NRD90M   Android            7.0       samsung   \n",
      "\n",
      "              version_id_31  screen_width  screen_height  had_id  tot_na  \n",
      "TransactionID                                                             \n",
      "2987000                 NaN           NaN            NaN     NaN     -12  \n",
      "2987001                 NaN           NaN            NaN     NaN     -16  \n",
      "2987002                 NaN           NaN            NaN     NaN     -35  \n",
      "2987003                 NaN           NaN            NaN     NaN     -19  \n",
      "2987004             browser          2220           1080     1.0    -119  \n",
      "\n",
      "[5 rows x 448 columns]\n",
      "               TransactionDT  TransactionAmt ProductCD  card1  card2  card3  \\\n",
      "TransactionID                                                                 \n",
      "3663549             18403224           31.95         W  10409  111.0  150.0   \n",
      "3663550             18403263           49.00         W   4272  111.0  150.0   \n",
      "3663551             18403310          171.00         W   4476  574.0  150.0   \n",
      "3663552             18403310          284.95         W  10989  360.0  150.0   \n",
      "3663553             18403317           67.95         W  18018  452.0  150.0   \n",
      "\n",
      "                    card4  card5  card6  addr1  ...  device_name  \\\n",
      "TransactionID                                   ...                \n",
      "3663549              visa  226.0  debit  170.0  ...          NaN   \n",
      "3663550              visa  226.0  debit  299.0  ...          NaN   \n",
      "3663551              visa  226.0  debit  472.0  ...          NaN   \n",
      "3663552              visa  166.0  debit  205.0  ...          NaN   \n",
      "3663553        mastercard  117.0  debit  264.0  ...          NaN   \n",
      "\n",
      "               device_version  OS_id_30 version_id_30 browser_id_31  \\\n",
      "TransactionID                                                         \n",
      "3663549                   NaN       NaN           NaN           NaN   \n",
      "3663550                   NaN       NaN           NaN           NaN   \n",
      "3663551                   NaN       NaN           NaN           NaN   \n",
      "3663552                   NaN       NaN           NaN           NaN   \n",
      "3663553                   NaN       NaN           NaN           NaN   \n",
      "\n",
      "               version_id_31  screen_width  screen_height  had_id  tot_na  \n",
      "TransactionID                                                              \n",
      "3663549                  NaN           NaN            NaN     NaN     -36  \n",
      "3663550                  NaN           NaN            NaN     NaN     -34  \n",
      "3663551                  NaN           NaN            NaN     NaN     -38  \n",
      "3663552                  NaN           NaN            NaN     NaN     -33  \n",
      "3663553                  NaN           NaN            NaN     NaN     -36  \n",
      "\n",
      "[5 rows x 447 columns]\n",
      "Mem. usage decreased to 689.34 Mb (65.6% reduction)\n",
      "Mem. usage decreased to 598.71 Mb (65.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##do not need to include right_index\n",
    "df_train = df_trans.merge(df_id, how='left', left_index=True,  on='TransactionID')\n",
    "df_test = df_test_trans.merge(df_test_id, how='left', left_index=True, on='TransactionID')\n",
    "\n",
    "#add total na for train and test data. \n",
    "df_train['tot_na'] = df_train.isna().sum(axis=1).astype(np.int8) \n",
    "df_test['tot_na'] = df_test.isna().sum(axis=1).astype(np.int8)\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "\n",
    "\n",
    "# y_train = df_train['isFraud'].copy()\n",
    "del df_trans, df_id, df_test_trans, df_test_id\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "##Deal with missing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1600'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[3577531,\"screen_height\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/davidcairuz/feature-engineering-lightgbm#\n",
    "#removed V300 feature\n",
    "useful_features = ['TransactionDT','TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1',\n",
    "                   'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13',\n",
    "                   'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M2', 'M3',\n",
    "                   'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V17',\n",
    "                   'V19', 'V20', 'V29', 'V30', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V40', 'V44', 'V45', 'V46', 'V47', 'V48',\n",
    "                   'V49', 'V51', 'V52', 'V53', 'V54', 'V56', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V69', 'V70', 'V71',\n",
    "                   'V72', 'V73', 'V74', 'V75', 'V76', 'V78', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V87', 'V90', 'V91', 'V92',\n",
    "                   'V93', 'V94', 'V95', 'V96', 'V97', 'V99', 'V100', 'V126', 'V127', 'V128', 'V130', 'V131', 'V138', 'V139', 'V140',\n",
    "                   'V143', 'V145', 'V146', 'V147', 'V149', 'V150', 'V151', 'V152', 'V154', 'V156', 'V158', 'V159', 'V160', 'V161',\n",
    "                   'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V169', 'V170', 'V171', 'V172', 'V173', 'V175', 'V176', 'V177',\n",
    "                   'V178', 'V180', 'V182', 'V184', 'V187', 'V188', 'V189', 'V195', 'V197', 'V200', 'V201', 'V202', 'V203', 'V204',\n",
    "                   'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V219', 'V220',\n",
    "                   'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V231', 'V233', 'V234', 'V238', 'V239',\n",
    "                   'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V249', 'V251', 'V253', 'V256', 'V257', 'V258', 'V259', 'V261',\n",
    "                   'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276',\n",
    "                   'V277', 'V278', 'V279', 'V280', 'V282', 'V283', 'V285', 'V287', 'V288', 'V289', 'V291', 'V292', 'V294','id_01',\n",
    "                   'id_02', 'id_03', 'id_05', 'id_06', 'id_09',\n",
    "                   'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_17', 'id_19', 'id_20', 'id_30', 'id_31', 'id_32', 'id_33',\n",
    "                   'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'device_name', 'device_version', 'OS_id_30', 'version_id_30',\n",
    "                   'browser_id_31', 'version_id_31', 'screen_width', 'screen_height', 'had_id','tot_na','C_sum','D_na','M_na','V_na','id_na']\n",
    "print(len(useful_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in df_train.columns if col not in useful_features]\n",
    "cols_to_drop.remove('isFraud')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(cols_to_drop, axis=1)\n",
    "df_test = df_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>device_name</th>\n",
       "      <th>device_version</th>\n",
       "      <th>OS_id_30</th>\n",
       "      <th>version_id_30</th>\n",
       "      <th>browser_id_31</th>\n",
       "      <th>version_id_31</th>\n",
       "      <th>screen_width</th>\n",
       "      <th>screen_height</th>\n",
       "      <th>had_id</th>\n",
       "      <th>tot_na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>NRD90M</td>\n",
       "      <td>Android</td>\n",
       "      <td>7.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>browser</td>\n",
       "      <td>2220</td>\n",
       "      <td>1080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577535</td>\n",
       "      <td>0</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>6550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577536</td>\n",
       "      <td>0</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>W</td>\n",
       "      <td>10444</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577537</td>\n",
       "      <td>0</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.953125</td>\n",
       "      <td>W</td>\n",
       "      <td>12037</td>\n",
       "      <td>595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577538</td>\n",
       "      <td>0</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>7826</td>\n",
       "      <td>481.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3577539</td>\n",
       "      <td>0</td>\n",
       "      <td>15811131</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>15066</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               isFraud  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "TransactionID                                                                   \n",
       "2987000              0          86400       68.500000         W  13926    NaN   \n",
       "2987001              0          86401       29.000000         W   2755  404.0   \n",
       "2987002              0          86469       59.000000         W   4663  490.0   \n",
       "2987003              0          86499       50.000000         W  18132  567.0   \n",
       "2987004              0          86506       50.000000         H   4497  514.0   \n",
       "...                ...            ...             ...       ...    ...    ...   \n",
       "3577535              0       15811047       49.000000         W   6550    NaN   \n",
       "3577536              0       15811049       39.500000         W  10444  225.0   \n",
       "3577537              0       15811079       30.953125         W  12037  595.0   \n",
       "3577538              0       15811088      117.000000         W   7826  481.0   \n",
       "3577539              0       15811131      280.000000         W  15066  170.0   \n",
       "\n",
       "               card3       card4  card5   card6  ...  device_name  \\\n",
       "TransactionID                                    ...                \n",
       "2987000        150.0    discover  142.0  credit  ...          NaN   \n",
       "2987001        150.0  mastercard  102.0  credit  ...          NaN   \n",
       "2987002        150.0        visa  166.0   debit  ...          NaN   \n",
       "2987003        150.0  mastercard  117.0   debit  ...          NaN   \n",
       "2987004        150.0  mastercard  102.0  credit  ...      Samsung   \n",
       "...              ...         ...    ...     ...  ...          ...   \n",
       "3577535        150.0        visa  226.0   debit  ...          NaN   \n",
       "3577536        150.0  mastercard  224.0   debit  ...          NaN   \n",
       "3577537        150.0  mastercard  224.0   debit  ...          NaN   \n",
       "3577538        150.0  mastercard  224.0   debit  ...          NaN   \n",
       "3577539        150.0  mastercard  102.0  credit  ...          NaN   \n",
       "\n",
       "               device_version  OS_id_30 version_id_30 browser_id_31  \\\n",
       "TransactionID                                                         \n",
       "2987000                   NaN       NaN           NaN           NaN   \n",
       "2987001                   NaN       NaN           NaN           NaN   \n",
       "2987002                   NaN       NaN           NaN           NaN   \n",
       "2987003                   NaN       NaN           NaN           NaN   \n",
       "2987004                NRD90M   Android           7.0       samsung   \n",
       "...                       ...       ...           ...           ...   \n",
       "3577535                   NaN       NaN           NaN           NaN   \n",
       "3577536                   NaN       NaN           NaN           NaN   \n",
       "3577537                   NaN       NaN           NaN           NaN   \n",
       "3577538                   NaN       NaN           NaN           NaN   \n",
       "3577539                   NaN       NaN           NaN           NaN   \n",
       "\n",
       "               version_id_31  screen_width  screen_height  had_id  tot_na  \n",
       "TransactionID                                                              \n",
       "2987000                  NaN           NaN            NaN     NaN     -12  \n",
       "2987001                  NaN           NaN            NaN     NaN     -16  \n",
       "2987002                  NaN           NaN            NaN     NaN     -35  \n",
       "2987003                  NaN           NaN            NaN     NaN     -19  \n",
       "2987004              browser          2220           1080     1.0    -119  \n",
       "...                      ...           ...            ...     ...     ...  \n",
       "3577535                  NaN           NaN            NaN     NaN     -16  \n",
       "3577536                  NaN           NaN            NaN     NaN     -34  \n",
       "3577537                  NaN           NaN            NaN     NaN     -29  \n",
       "3577538                  NaN           NaN            NaN     NaN     -35  \n",
       "3577539                  NaN           NaN            NaN     NaN     -34  \n",
       "\n",
       "[590540 rows x 274 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               isFraud  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
      "TransactionID                                                                   \n",
      "2987000              0          86400       68.500000         W  13926    NaN   \n",
      "2987001              0          86401       29.000000         W   2755  404.0   \n",
      "2987002              0          86469       59.000000         W   4663  490.0   \n",
      "2987003              0          86499       50.000000         W  18132  567.0   \n",
      "2987004              0          86506       50.000000         H   4497  514.0   \n",
      "...                ...            ...             ...       ...    ...    ...   \n",
      "3577535              0       15811047       49.000000         W   6550    NaN   \n",
      "3577536              0       15811049       39.500000         W  10444  225.0   \n",
      "3577537              0       15811079       30.953125         W  12037  595.0   \n",
      "3577538              0       15811088      117.000000         W   7826  481.0   \n",
      "3577539              0       15811131      280.000000         W  15066  170.0   \n",
      "\n",
      "               card3       card4  card5   card6  ...  device_name  \\\n",
      "TransactionID                                    ...                \n",
      "2987000        150.0    discover  142.0  credit  ...          NaN   \n",
      "2987001        150.0  mastercard  102.0  credit  ...          NaN   \n",
      "2987002        150.0        visa  166.0   debit  ...          NaN   \n",
      "2987003        150.0  mastercard  117.0   debit  ...          NaN   \n",
      "2987004        150.0  mastercard  102.0  credit  ...      Samsung   \n",
      "...              ...         ...    ...     ...  ...          ...   \n",
      "3577535        150.0        visa  226.0   debit  ...          NaN   \n",
      "3577536        150.0  mastercard  224.0   debit  ...          NaN   \n",
      "3577537        150.0  mastercard  224.0   debit  ...          NaN   \n",
      "3577538        150.0  mastercard  224.0   debit  ...          NaN   \n",
      "3577539        150.0  mastercard  102.0  credit  ...          NaN   \n",
      "\n",
      "               device_version  OS_id_30 version_id_30 browser_id_31  \\\n",
      "TransactionID                                                         \n",
      "2987000                   NaN       NaN           NaN           NaN   \n",
      "2987001                   NaN       NaN           NaN           NaN   \n",
      "2987002                   NaN       NaN           NaN           NaN   \n",
      "2987003                   NaN       NaN           NaN           NaN   \n",
      "2987004                NRD90M   Android           7.0       samsung   \n",
      "...                       ...       ...           ...           ...   \n",
      "3577535                   NaN       NaN           NaN           NaN   \n",
      "3577536                   NaN       NaN           NaN           NaN   \n",
      "3577537                   NaN       NaN           NaN           NaN   \n",
      "3577538                   NaN       NaN           NaN           NaN   \n",
      "3577539                   NaN       NaN           NaN           NaN   \n",
      "\n",
      "               version_id_31  screen_width  screen_height  had_id  tot_na  \n",
      "TransactionID                                                              \n",
      "2987000                  NaN           NaN            NaN     NaN     -12  \n",
      "2987001                  NaN           NaN            NaN     NaN     -16  \n",
      "2987002                  NaN           NaN            NaN     NaN     -35  \n",
      "2987003                  NaN           NaN            NaN     NaN     -19  \n",
      "2987004              browser          2220           1080     1.0    -119  \n",
      "...                      ...           ...            ...     ...     ...  \n",
      "3577535                  NaN           NaN            NaN     NaN     -16  \n",
      "3577536                  NaN           NaN            NaN     NaN     -34  \n",
      "3577537                  NaN           NaN            NaN     NaN     -29  \n",
      "3577538                  NaN           NaN            NaN     NaN     -35  \n",
      "3577539                  NaN           NaN            NaN     NaN     -34  \n",
      "\n",
      "[590540 rows x 274 columns]\n",
      "               TransactionDT  TransactionAmt ProductCD  card1  card2  card3  \\\n",
      "TransactionID                                                                 \n",
      "3663549             18403224       31.953125         W  10409  111.0  150.0   \n",
      "3663550             18403263       49.000000         W   4272  111.0  150.0   \n",
      "3663551             18403310      171.000000         W   4476  574.0  150.0   \n",
      "3663552             18403310      285.000000         W  10989  360.0  150.0   \n",
      "3663553             18403317       67.937500         W  18018  452.0  150.0   \n",
      "...                      ...             ...       ...    ...    ...    ...   \n",
      "4170235             34214279       94.687500         C  13832  375.0  185.0   \n",
      "4170236             34214287       12.171875         C   3154  408.0  185.0   \n",
      "4170237             34214326       49.000000         W  16661  490.0  150.0   \n",
      "4170238             34214337      202.000000         W  16621  516.0  150.0   \n",
      "4170239             34214345       24.343750         C   5713  168.0  144.0   \n",
      "\n",
      "                    card4  card5   card6  addr1  ...  device_name  \\\n",
      "TransactionID                                    ...                \n",
      "3663549              visa  226.0   debit  170.0  ...          NaN   \n",
      "3663550              visa  226.0   debit  299.0  ...          NaN   \n",
      "3663551              visa  226.0   debit  472.0  ...          NaN   \n",
      "3663552              visa  166.0   debit  205.0  ...          NaN   \n",
      "3663553        mastercard  117.0   debit  264.0  ...          NaN   \n",
      "...                   ...    ...     ...    ...  ...          ...   \n",
      "4170235        mastercard  224.0   debit  284.0  ...          NaN   \n",
      "4170236        mastercard  224.0   debit    NaN  ...       Huawei   \n",
      "4170237              visa  226.0   debit  327.0  ...          NaN   \n",
      "4170238        mastercard  224.0   debit  177.0  ...          NaN   \n",
      "4170239              visa  147.0  credit    NaN  ...      Samsung   \n",
      "\n",
      "               device_version OS_id_30 version_id_30  browser_id_31  \\\n",
      "TransactionID                                                         \n",
      "3663549                   NaN      NaN           NaN            NaN   \n",
      "3663550                   NaN      NaN           NaN            NaN   \n",
      "3663551                   NaN      NaN           NaN            NaN   \n",
      "3663552                   NaN      NaN           NaN            NaN   \n",
      "3663553                   NaN      NaN           NaN            NaN   \n",
      "...                       ...      ...           ...            ...   \n",
      "4170235                   NaN      NaN           NaN            NaN   \n",
      "4170236         HuaweiALE-L23      NaN           NaN         chrome   \n",
      "4170237                   NaN      NaN           NaN            NaN   \n",
      "4170238                   NaN      NaN           NaN            NaN   \n",
      "4170239                  None      NaN           NaN        samsung   \n",
      "\n",
      "               version_id_31  screen_width  screen_height  had_id  tot_na  \n",
      "TransactionID                                                              \n",
      "3663549                  NaN           NaN            NaN     NaN     -36  \n",
      "3663550                  NaN           NaN            NaN     NaN     -34  \n",
      "3663551                  NaN           NaN            NaN     NaN     -38  \n",
      "3663552                  NaN           NaN            NaN     NaN     -33  \n",
      "3663553                  NaN           NaN            NaN     NaN     -36  \n",
      "...                      ...           ...            ...     ...     ...  \n",
      "4170235                  NaN           NaN            NaN     NaN     -17  \n",
      "4170236                 43.0           NaN            NaN     1.0      94  \n",
      "4170237                  NaN           NaN            NaN     NaN     -34  \n",
      "4170238                  NaN           NaN            NaN     NaN     -34  \n",
      "4170239              browser           NaN            NaN     1.0      95  \n",
      "\n",
      "[506691 rows x 273 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new feature regarding TransactionDT\n",
    "# any repeated transation consecutively under one card1 number is very suspicious. \n",
    "df_train= df_train.sort_values(by =['card1','TransactionDT'])\n",
    "\n",
    "rpt_trans = [1  if df_train.iloc[i,2] == df_train.iloc[i+1,2] or df_train.iloc[i,2] == df_train.iloc[i-1,2] else 0 for i in range(1,df_train.shape[0]-1)]\n",
    "df_train['rept_trans'] =[0]+ rpt_trans +[0]\n",
    "\n",
    "df_test= df_test.sort_values(by =['card1','TransactionDT'])\n",
    "\n",
    "rpt_trans = [1  if df_test.iloc[i,2] == df_test.iloc[i+1,2] or df_test.iloc[i,2] == df_test.iloc[i-1,2] else 0 for i in range(1,df_test.shape[0]-1)]\n",
    "df_test['rept_trans'] =[0]+ rpt_trans +[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "########################### Vars\n",
    "#################################################################################\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = False\n",
    "MAKE_MODEL_TEST = False\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    TARGET,\n",
    "    ]\n",
    "\n",
    "base_columns = [col for col in list(df_train) if col not in remove_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TransactionDT\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "dates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\n",
    "us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n",
    "\n",
    "# Let's add temporary \"time variables\" for aggregations\n",
    "# and add normal \"time variables\"\n",
    "for df in [df_train, df_test]:\n",
    "    \n",
    "    # Temporary variables for aggregation\n",
    "    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    df['DT_M'] = ((df['DT'].dt.year-2017)*12 + df['DT'].dt.month).astype(np.int8)\n",
    "    df['DT_W'] = ((df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear).astype(np.int8)\n",
    "    df['DT_D'] = ((df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear).astype(np.int16)\n",
    "    \n",
    "    df['DT_hour'] = (df['DT'].dt.hour).astype(np.int8)\n",
    "    df['DT_day_week'] = (df['DT'].dt.dayofweek).astype(np.int8)\n",
    "    df['DT_day_month'] = (df['DT'].dt.day).astype(np.int8)\n",
    "        \n",
    "    # Possible solo feature\n",
    "    df['is_december'] = df['DT'].dt.month\n",
    "    df['is_december'] = (df['is_december']==12).astype(np.int8)\n",
    "\n",
    "    # Holidays\n",
    "    df['is_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "\n",
    "# Remove temporary features from final list\n",
    "remove_features += ['DT','DT_M','DT_W','DT_D','DT_hour','DT_day_week','DT_day_month']\n",
    "    \n",
    "# Total transactions per timeblock\n",
    "for col in ['DT_M','DT_W','DT_D']:\n",
    "    temp_df = pd.concat([df_train[[col]], df_test[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()\n",
    "            \n",
    "    df_train[col+'_total'] = df_train[col].map(fq_encode)\n",
    "    df_test[col+'_total']  = df_test[col].map(fq_encode)\n",
    "    \n",
    "    # We can't use it as solo feature\n",
    "    remove_features.append(col+'_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoding(df_train, df_test, columns, self_encoding=False):\n",
    "    for col in columns:\n",
    "        temp_df = pd.concat([df_train[[col]], df_test[[col]]])\n",
    "        fq_encode = temp_df[col].value_counts(dropna=False).to_dict()\n",
    "        if self_encoding:\n",
    "            df_train[col] = df_train[col].map(fq_encode)\n",
    "            df_test[col]  = df_test[col].map(fq_encode)            \n",
    "        else:\n",
    "            df_train[col+'_fq_enc'] = df_train[col].map(fq_encode)\n",
    "            df_test[col+'_fq_enc']  = df_test[col].map(fq_encode)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Most common uIds:\n",
      "########## uid\n",
      "7919_194.0     14891\n",
      "9500_321.0     14112\n",
      "15885_545.0    10332\n",
      "17188_321.0    10312\n",
      "15066_170.0     7918\n",
      "12695_490.0     7079\n",
      "6019_583.0      6766\n",
      "12544_321.0     6760\n",
      "2803_100.0      6126\n",
      "7585_553.0      5325\n",
      "Name: uid, dtype: int64\n",
      "########## uid2\n",
      "9500_321.0_150.0_226.0     14112\n",
      "15885_545.0_185.0_138.0    10332\n",
      "17188_321.0_150.0_226.0    10312\n",
      "7919_194.0_150.0_166.0      8844\n",
      "15066_170.0_150.0_102.0     7918\n",
      "12695_490.0_150.0_226.0     7079\n",
      "6019_583.0_150.0_226.0      6766\n",
      "12544_321.0_150.0_226.0     6760\n",
      "2803_100.0_150.0_226.0      6126\n",
      "7919_194.0_150.0_202.0      6047\n",
      "Name: uid2, dtype: int64\n",
      "########## uid3\n",
      "15885_545.0_185.0_138.0_nan_nan       9900\n",
      "17188_321.0_150.0_226.0_299.0_87.0    5862\n",
      "12695_490.0_150.0_226.0_325.0_87.0    5766\n",
      "9500_321.0_150.0_226.0_204.0_87.0     4647\n",
      "3154_408.0_185.0_224.0_nan_nan        4398\n",
      "12839_321.0_150.0_226.0_264.0_87.0    3538\n",
      "16132_111.0_150.0_226.0_299.0_87.0    3523\n",
      "15497_490.0_150.0_226.0_299.0_87.0    3419\n",
      "9500_321.0_150.0_226.0_272.0_87.0     2715\n",
      "5812_408.0_185.0_224.0_nan_nan        2639\n",
      "Name: uid3, dtype: int64\n",
      "########## uid4\n",
      "15885_545.0_185.0_138.0_nan_nan_hotmail.com     4002\n",
      "15885_545.0_185.0_138.0_nan_nan_gmail.com       3830\n",
      "17188_321.0_150.0_226.0_299.0_87.0_gmail.com    2235\n",
      "12695_490.0_150.0_226.0_325.0_87.0_gmail.com    2045\n",
      "9500_321.0_150.0_226.0_204.0_87.0_gmail.com     1947\n",
      "3154_408.0_185.0_224.0_nan_nan_hotmail.com      1890\n",
      "3154_408.0_185.0_224.0_nan_nan_gmail.com        1537\n",
      "12839_321.0_150.0_226.0_264.0_87.0_gmail.com    1473\n",
      "15775_481.0_150.0_102.0_330.0_87.0_nan          1453\n",
      "15497_490.0_150.0_226.0_299.0_87.0_gmail.com    1383\n",
      "Name: uid4, dtype: int64\n",
      "########## uid5\n",
      "12695_490.0_150.0_226.0_325.0_87.0_nan         5446\n",
      "17188_321.0_150.0_226.0_299.0_87.0_nan         5322\n",
      "9500_321.0_150.0_226.0_204.0_87.0_nan          4403\n",
      "15885_545.0_185.0_138.0_nan_nan_hotmail.com    4002\n",
      "15885_545.0_185.0_138.0_nan_nan_gmail.com      3830\n",
      "12839_321.0_150.0_226.0_264.0_87.0_nan         3365\n",
      "16132_111.0_150.0_226.0_299.0_87.0_nan         3212\n",
      "15497_490.0_150.0_226.0_299.0_87.0_nan         3027\n",
      "9500_321.0_150.0_226.0_272.0_87.0_nan          2601\n",
      "7664_490.0_150.0_226.0_264.0_87.0_nan          2396\n",
      "Name: uid5, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################### Client Virtual ID\n",
    "# Let's add some kind of client uID based on cardID and addr columns\n",
    "# The value will be very specific for each client so we need to remove it\n",
    "# from final features. But we can use it for aggregations.\n",
    "df_train['uid'] = df_train['card1'].astype(str)+'_'+df_train['card2'].astype(str)\n",
    "df_test['uid'] = df_test['card1'].astype(str)+'_'+df_test['card2'].astype(str)\n",
    "\n",
    "df_train['uid2'] = df_train['uid'].astype(str)+'_'+df_train['card3'].astype(str)+'_'+df_train['card5'].astype(str)\n",
    "df_test['uid2'] = df_test['uid'].astype(str)+'_'+df_test['card3'].astype(str)+'_'+df_test['card5'].astype(str)\n",
    "\n",
    "df_train['uid3'] = df_train['uid2'].astype(str)+'_'+df_train['addr1'].astype(str)+'_'+df_train['addr2'].astype(str)\n",
    "df_test['uid3'] = df_test['uid2'].astype(str)+'_'+df_test['addr1'].astype(str)+'_'+df_test['addr2'].astype(str)\n",
    "\n",
    "df_train['uid4'] = df_train['uid3'].astype(str)+'_'+df_train['P_emaildomain'].astype(str)\n",
    "df_test['uid4'] = df_test['uid3'].astype(str)+'_'+df_test['P_emaildomain'].astype(str)\n",
    "\n",
    "df_train['uid5'] = df_train['uid3'].astype(str)+'_'+df_train['R_emaildomain'].astype(str)\n",
    "df_test['uid5'] = df_test['uid3'].astype(str)+'_'+df_test['R_emaildomain'].astype(str)\n",
    "\n",
    "# Add values remove list\n",
    "new_columns = ['uid','uid2','uid3','uid4','uid5']\n",
    "remove_features += new_columns\n",
    "\n",
    "print('#'*10)\n",
    "print('Most common uIds:')\n",
    "for col in new_columns:\n",
    "    print('#'*10, col)\n",
    "    print(df_train[col].value_counts()[:10])\n",
    "\n",
    "# Do Global frequency encoding \n",
    "i_cols = ['card1','card2','card3','card5'] + new_columns\n",
    "df_train, df_test = frequency_encoding(df_train, df_test, i_cols, self_encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['TransactionID'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-68110884c853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m########################### Merge Identity columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TransactionID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TransactionID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TransactionID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 raise KeyError(\n\u001b[0;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1177\u001b[1;33m                         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m                     )\n\u001b[0;32m   1179\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['TransactionID'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "########################### Device info and identity\n",
    "for df in [df_id, df_test_id]:\n",
    "    ########################### Device info\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "    df['DeviceInfo_device'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['DeviceInfo_version'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Device info 2\n",
    "    df['id_30'] = df['id_30'].fillna('unknown_device').str.lower()\n",
    "    df['id_30_device'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['id_30_version'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Browser\n",
    "    df['id_31'] = df['id_31'].fillna('unknown_device').str.lower()\n",
    "    df['id_31_device'] = df['id_31'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    \n",
    "########################### Merge Identity columns\n",
    "temp_df = df_train[['TransactionID']]\n",
    "temp_df = temp_df.merge(df_id, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "df_train = pd.concat([df_train,temp_df], axis=1)\n",
    "    \n",
    "temp_df = df_test[['TransactionID']]\n",
    "temp_df = temp_df.merge(df_test_id, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "df_test = pd.concat([df_test,temp_df], axis=1)\n",
    "\n",
    "i_cols = [\n",
    "          'DeviceInfo','DeviceInfo_device','DeviceInfo_version',\n",
    "          'id_30','id_30_device','id_30_version',\n",
    "          'id_31','id_31_device',\n",
    "          'id_33',\n",
    "         ]\n",
    "\n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "df_train, df_test = frequency_encoding(df_train, df_test, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### ProductCD and M4 Target mean\n",
    "# As we already have frequency encoded columns\n",
    "# We can have different global transformation on them\n",
    "# Target mean?\n",
    "# We will transform original values as we don't need them\n",
    "# Leakage over folds?\n",
    "# Yes, we will have some,\n",
    "# But in the same time we already have leakage from \n",
    "# V columns and card1->card6 columns\n",
    "# So, no much harm here\n",
    "for col in ['ProductCD','M4']:\n",
    "    temp_dict = df_train.groupby([col])[TARGET].agg(['mean']).reset_index().rename(\n",
    "                                                        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    df_train[col] = df_train[col].map(temp_dict)\n",
    "    df_test[col]  = df_test[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card4\n",
      "card6\n",
      "P_emaildomain\n",
      "R_emaildomain\n",
      "M2\n",
      "M3\n",
      "M5\n",
      "M6\n",
      "M7\n",
      "M8\n",
      "M9\n",
      "id_12\n",
      "id_15\n",
      "id_30\n",
      "id_31\n",
      "id_33\n",
      "id_36\n",
      "id_37\n",
      "id_38\n",
      "DeviceType\n",
      "DeviceInfo\n",
      "device_name\n",
      "device_version\n",
      "OS_id_30\n",
      "version_id_30\n",
      "browser_id_31\n",
      "version_id_31\n",
      "screen_width\n",
      "screen_height\n",
      "uid\n",
      "uid2\n",
      "uid3\n",
      "uid4\n",
      "uid5\n"
     ]
    }
   ],
   "source": [
    "########################### Encode Str columns\n",
    "# For all such columns (probably not)\n",
    "# we already did frequency encoding (numeric feature)\n",
    "# so we will use astype('category') here\n",
    "for col in list(df_train):\n",
    "    if df_train[col].dtype=='O':\n",
    "        print(col)\n",
    "        df_train[col] = df_train[col].fillna('unseen_before_label')\n",
    "        df_test[col]  = df_test[col].fillna('unseen_before_label')\n",
    "        \n",
    "        df_train[col] = df_train[col].astype(str)\n",
    "        df_test[col] = df_test[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(df_train[col])+list(df_test[col]))\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col]  = le.transform(df_test[col])\n",
    "        \n",
    "        df_train[col] = df_train[col].astype('category')\n",
    "        df_test[col] = df_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added card6 - debit credit\n",
    "#columns_a = ['TransactionAmt', 'id_02', 'D15']\n",
    "#columns_b = ['card1', 'card2']\n",
    "\n",
    "#for col_a in columns_a:\n",
    "#    for col_b in columns_b:\n",
    "#        for df in [df_train, df_test]:\n",
    "#            df[f'{col_a}_to_mean_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('mean')\n",
    "#            df[f'{col_a}_to_std_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature - log of transaction amount.\n",
    "#df_train['TransactionAmt_Log'] = np.log(df_train['TransactionAmt'])\n",
    "#df_test['TransactionAmt_Log'] = np.log(df_test['TransactionAmt'])\n",
    "\n",
    "# New feature - decimal part of the transaction amount.\n",
    "df_train['TransactionAmt_decimal'] = ((df_train['TransactionAmt'] - df_train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "df_test['TransactionAmt_decimal'] = ((df_test['TransactionAmt'] - df_test['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "\n",
    "# New feature - day of week in which a transaction happened.\n",
    "df_train['Transaction_day_of_week'] = np.floor((df_train['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "df_test['Transaction_day_of_week'] = np.floor((df_test['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "\n",
    "# New feature - hour of the day in which a transaction happened.\n",
    "df_train['Transaction_hour'] = np.floor(df_train['TransactionDT'] / 3600) % 24\n",
    "df_test['Transaction_hour'] = np.floor(df_test['TransactionDT'] / 3600) % 24\n",
    "\n",
    "# Some arbitrary features interaction\n",
    "for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain',\n",
    "                'card2__dist1', 'card1__card5', 'card2__id_20', 'card1__P_emaildomain', 'addr1__card1']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    df_train[feature] = df_train[f1].astype(str) + '_' + df_train[f2].astype(str)\n",
    "    df_test[feature] = df_test[f1].astype(str) + '_' + df_test[f2].astype(str)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(list(df_train[feature].astype(str).values) + list(df_test[feature].astype(str).values))\n",
    "    df_train[feature] = le.transform(list(df_train[feature].astype(str).values))\n",
    "    df_test[feature] = le.transform(list(df_test[feature].astype(str).values))\n",
    "\n",
    "# Encoding - count encoding for both df_train and df_test\n",
    "for feature in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'id_36']:\n",
    "    df_train[feature + '_count_full'] = df_train[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    df_test[feature + '_count_full'] = df_test[feature].map(pd.concat([df_train[feature], df_test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# Encoding - count encoding separately for df_train and df_test\n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_36']:\n",
    "    df_train[feature + '_count_dist'] = df_train[feature].map(df_train[feature].value_counts(dropna=False))\n",
    "    df_test[feature + '_count_dist'] = df_test[feature].map(df_test[feature].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>card2_count_full</th>\n",
       "      <th>card3_count_full</th>\n",
       "      <th>card4_count_full</th>\n",
       "      <th>card5_count_full</th>\n",
       "      <th>card6_count_full</th>\n",
       "      <th>id_36_count_full</th>\n",
       "      <th>id_01_count_dist</th>\n",
       "      <th>id_31_count_dist</th>\n",
       "      <th>id_33_count_dist</th>\n",
       "      <th>id_36_count_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3230924</td>\n",
       "      <td>0</td>\n",
       "      <td>5787419</td>\n",
       "      <td>23.4375</td>\n",
       "      <td>0.116873</td>\n",
       "      <td>1000</td>\n",
       "      <td>555.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80404</td>\n",
       "      <td>109960</td>\n",
       "      <td>347386</td>\n",
       "      <td>153109</td>\n",
       "      <td>824959</td>\n",
       "      <td>267353</td>\n",
       "      <td>82170</td>\n",
       "      <td>5806</td>\n",
       "      <td>517251</td>\n",
       "      <td>134066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3023634</td>\n",
       "      <td>0</td>\n",
       "      <td>916268</td>\n",
       "      <td>183.0000</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>1001</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80404</td>\n",
       "      <td>956845</td>\n",
       "      <td>719649</td>\n",
       "      <td>553537</td>\n",
       "      <td>824959</td>\n",
       "      <td>819269</td>\n",
       "      <td>446307</td>\n",
       "      <td>450258</td>\n",
       "      <td>517251</td>\n",
       "      <td>449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3151336</td>\n",
       "      <td>0</td>\n",
       "      <td>3504180</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>1001</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80404</td>\n",
       "      <td>956845</td>\n",
       "      <td>719649</td>\n",
       "      <td>553537</td>\n",
       "      <td>824959</td>\n",
       "      <td>819269</td>\n",
       "      <td>446307</td>\n",
       "      <td>450258</td>\n",
       "      <td>517251</td>\n",
       "      <td>449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3210739</td>\n",
       "      <td>0</td>\n",
       "      <td>5270458</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>1001</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80404</td>\n",
       "      <td>956845</td>\n",
       "      <td>719649</td>\n",
       "      <td>553537</td>\n",
       "      <td>824959</td>\n",
       "      <td>819269</td>\n",
       "      <td>446307</td>\n",
       "      <td>450258</td>\n",
       "      <td>517251</td>\n",
       "      <td>449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3020767</td>\n",
       "      <td>0</td>\n",
       "      <td>842821</td>\n",
       "      <td>150.0000</td>\n",
       "      <td>0.037826</td>\n",
       "      <td>1004</td>\n",
       "      <td>583.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41503</td>\n",
       "      <td>956845</td>\n",
       "      <td>719649</td>\n",
       "      <td>553537</td>\n",
       "      <td>267648</td>\n",
       "      <td>267353</td>\n",
       "      <td>82170</td>\n",
       "      <td>22000</td>\n",
       "      <td>263</td>\n",
       "      <td>134066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590535</td>\n",
       "      <td>3419314</td>\n",
       "      <td>0</td>\n",
       "      <td>10938204</td>\n",
       "      <td>232.5000</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>18395</td>\n",
       "      <td>543.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9968</td>\n",
       "      <td>956845</td>\n",
       "      <td>347386</td>\n",
       "      <td>153109</td>\n",
       "      <td>824959</td>\n",
       "      <td>819269</td>\n",
       "      <td>446307</td>\n",
       "      <td>450258</td>\n",
       "      <td>517251</td>\n",
       "      <td>449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590536</td>\n",
       "      <td>3420746</td>\n",
       "      <td>0</td>\n",
       "      <td>10964952</td>\n",
       "      <td>36.9375</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>18395</td>\n",
       "      <td>543.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9968</td>\n",
       "      <td>956845</td>\n",
       "      <td>347386</td>\n",
       "      <td>153109</td>\n",
       "      <td>824959</td>\n",
       "      <td>819269</td>\n",
       "      <td>446307</td>\n",
       "      <td>450258</td>\n",
       "      <td>517251</td>\n",
       "      <td>449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590537</td>\n",
       "      <td>3446622</td>\n",
       "      <td>0</td>\n",
       "      <td>11806909</td>\n",
       "      <td>36.9375</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>18395</td>\n",
       "      <td>543.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9968</td>\n",
       "      <td>956845</td>\n",
       "      <td>347386</td>\n",
       "      <td>153109</td>\n",
       "      <td>824959</td>\n",
       "      <td>819269</td>\n",
       "      <td>446307</td>\n",
       "      <td>450258</td>\n",
       "      <td>517251</td>\n",
       "      <td>449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590538</td>\n",
       "      <td>3480204</td>\n",
       "      <td>0</td>\n",
       "      <td>12865537</td>\n",
       "      <td>36.9375</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>18395</td>\n",
       "      <td>543.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9968</td>\n",
       "      <td>956845</td>\n",
       "      <td>347386</td>\n",
       "      <td>153109</td>\n",
       "      <td>824959</td>\n",
       "      <td>819269</td>\n",
       "      <td>446307</td>\n",
       "      <td>450258</td>\n",
       "      <td>517251</td>\n",
       "      <td>449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590539</td>\n",
       "      <td>3102181</td>\n",
       "      <td>0</td>\n",
       "      <td>2231501</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.037826</td>\n",
       "      <td>18396</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82537</td>\n",
       "      <td>956845</td>\n",
       "      <td>719649</td>\n",
       "      <td>553537</td>\n",
       "      <td>824959</td>\n",
       "      <td>267353</td>\n",
       "      <td>82170</td>\n",
       "      <td>9030</td>\n",
       "      <td>517251</td>\n",
       "      <td>134066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  isFraud  TransactionDT  TransactionAmt  ProductCD  \\\n",
       "0             3230924        0        5787419         23.4375   0.116873   \n",
       "1             3023634        0         916268        183.0000   0.020399   \n",
       "2             3151336        0        3504180         29.0000   0.020399   \n",
       "3             3210739        0        5270458         27.0000   0.020399   \n",
       "4             3020767        0         842821        150.0000   0.037826   \n",
       "...               ...      ...            ...             ...        ...   \n",
       "590535        3419314        0       10938204        232.5000   0.020399   \n",
       "590536        3420746        0       10964952         36.9375   0.020399   \n",
       "590537        3446622        0       11806909         36.9375   0.020399   \n",
       "590538        3480204        0       12865537         36.9375   0.020399   \n",
       "590539        3102181        0        2231501        100.0000   0.037826   \n",
       "\n",
       "        card1  card2  card3 card4  card5  ... card2_count_full  \\\n",
       "0        1000  555.0  185.0     2  224.0  ...            80404   \n",
       "1        1001  555.0  150.0     4  226.0  ...            80404   \n",
       "2        1001  555.0  150.0     4  226.0  ...            80404   \n",
       "3        1001  555.0  150.0     4  226.0  ...            80404   \n",
       "4        1004  583.0  150.0     4  226.0  ...            41503   \n",
       "...       ...    ...    ...   ...    ...  ...              ...   \n",
       "590535  18395  543.0  150.0     2  224.0  ...             9968   \n",
       "590536  18395  543.0  150.0     2  224.0  ...             9968   \n",
       "590537  18395  543.0  150.0     2  224.0  ...             9968   \n",
       "590538  18395  543.0  150.0     2  224.0  ...             9968   \n",
       "590539  18396  111.0  150.0     4  226.0  ...            82537   \n",
       "\n",
       "        card3_count_full  card4_count_full  card5_count_full card6_count_full  \\\n",
       "0                 109960            347386            153109           824959   \n",
       "1                 956845            719649            553537           824959   \n",
       "2                 956845            719649            553537           824959   \n",
       "3                 956845            719649            553537           824959   \n",
       "4                 956845            719649            553537           267648   \n",
       "...                  ...               ...               ...              ...   \n",
       "590535            956845            347386            153109           824959   \n",
       "590536            956845            347386            153109           824959   \n",
       "590537            956845            347386            153109           824959   \n",
       "590538            956845            347386            153109           824959   \n",
       "590539            956845            719649            553537           824959   \n",
       "\n",
       "       id_36_count_full  id_01_count_dist  id_31_count_dist  id_33_count_dist  \\\n",
       "0                267353             82170              5806            517251   \n",
       "1                819269            446307            450258            517251   \n",
       "2                819269            446307            450258            517251   \n",
       "3                819269            446307            450258            517251   \n",
       "4                267353             82170             22000               263   \n",
       "...                 ...               ...               ...               ...   \n",
       "590535           819269            446307            450258            517251   \n",
       "590536           819269            446307            450258            517251   \n",
       "590537           819269            446307            450258            517251   \n",
       "590538           819269            446307            450258            517251   \n",
       "590539           267353             82170              9030            517251   \n",
       "\n",
       "        id_36_count_dist  \n",
       "0                 134066  \n",
       "1                 449555  \n",
       "2                 449555  \n",
       "3                 449555  \n",
       "4                 134066  \n",
       "...                  ...  \n",
       "590535            449555  \n",
       "590536            449555  \n",
       "590537            449555  \n",
       "590538            449555  \n",
       "590539            134066  \n",
       "\n",
       "[590540 rows x 325 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.reset_index()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "card1\n",
      "card2\n",
      "addr1\n",
      "addr1__card1\n",
      "card1__card5\n",
      "card1__P_emaildomain\n",
      "Fold: 2\n",
      "card1\n",
      "card2\n",
      "addr1\n",
      "addr1__card1\n",
      "card1__card5\n",
      "card1__P_emaildomain\n",
      "Fold: 3\n",
      "card1\n",
      "card2\n",
      "addr1\n",
      "addr1__card1\n",
      "card1__card5\n",
      "card1__P_emaildomain\n",
      "Fold: 4\n",
      "card1\n",
      "card2\n",
      "addr1\n",
      "addr1__card1\n",
      "card1__card5\n",
      "card1__P_emaildomain\n",
      "Fold: 5\n",
      "card1\n",
      "card2\n",
      "addr1\n",
      "addr1__card1\n",
      "card1__card5\n",
      "card1__P_emaildomain\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#k fold cross validation target mean coding to avoid overfitting\n",
    "\n",
    "N_SPLITS = 5\n",
    "SEED = 6\n",
    "\n",
    "folds = KFold(n_splits=N_SPLITS,shuffle = False, random_state=SEED)\n",
    "# Test Data and expport DF\n",
    "  \n",
    "score = 0\n",
    "y_result = 0\n",
    "\n",
    "mean_of_target = df_train['isFraud'].mean()\n",
    "\n",
    "target_mean_list =['card1','card2','addr1','addr1__card1','card1__card5','card1__P_emaildomain']\n",
    "\n",
    "# kfold target mean encoding for regularisation\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x = df_train.iloc[trn_idx,:] \n",
    "    vl_x = df_train.iloc[val_idx,:]  \n",
    "    \n",
    "    for col in target_mean_list:\n",
    "        print(col)\n",
    "        df_train.loc[val_idx,f'{col}_target_enc'] = vl_x[col].map(tr_x.groupby(col)['isFraud'].mean())\n",
    "        \n",
    "        df_train[f'{col}_target_enc'].fillna(mean_of_target, inplace = True)\n",
    "                                                        \n",
    "for col in target_mean_list:\n",
    "                                                            \n",
    "    df_test[f'{col}_target_enc'] = df_test[col].map(df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "\n",
    "    df_test[f'{col}_target_enc'].fillna(mean_of_target, inplace = True)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uid_aggregation(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "def uid_aggregation_and_normalization(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            \n",
    "            new_norm_col_name = col+'_'+main_column+'_std_norm'\n",
    "            norm_cols = []\n",
    "            \n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "                norm_cols.append(new_col_name)\n",
    "            \n",
    "            train_df[new_norm_col_name] = (train_df[main_column]-train_df[norm_cols[0]])/train_df[norm_cols[1]]\n",
    "            test_df[new_norm_col_name]  = (test_df[main_column]-test_df[norm_cols[0]])/test_df[norm_cols[1]]          \n",
    "            \n",
    "            del train_df[norm_cols[0]], train_df[norm_cols[1]]\n",
    "            del test_df[norm_cols[0]], test_df[norm_cols[1]]\n",
    "                                              \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['bank_type'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-c5fd94ba2733>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m####### uIDs aggregations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muid_aggregation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m####### Cleaning Neagtive values and columns transformations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-d1cb61fb00ac>\u001b[0m in \u001b[0;36muid_aggregation\u001b[1;34m(train_df, test_df, main_columns, uids, aggregations)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0magg_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maggregations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mnew_col_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmain_column\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0magg_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                 \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmain_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n\u001b[0;32m      8\u001b[0m                                                         columns={agg_type: new_col_name})\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\oem\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['bank_type'] not in index\""
     ]
    }
   ],
   "source": [
    "########################### D Columns\n",
    "# From columns description we know that\n",
    "# D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "# 1. I can't imagine normal negative timedelta values (Let's clip Values)\n",
    "# 2. Normalize (Min-Max, Standard score) All D columns, except D1,D2,D9\n",
    "# 3. Do some aggregations based on uIDs\n",
    "# 4. Freaquency encoding\n",
    "# 5. D1,D2 are clipped by max df_train values (let's scale it)\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "uids = ['uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "aggregations = ['mean','std']\n",
    "\n",
    "####### uIDs aggregations\n",
    "df_train, df_test = uid_aggregation(df_train, df_test, i_cols, uids, aggregations)\n",
    "\n",
    "####### Cleaning Neagtive values and columns transformations\n",
    "for df in [df_train, df_test]:\n",
    "\n",
    "    for col in i_cols:\n",
    "        df[col] = df[col].clip(0) \n",
    "    \n",
    "    # Lets transform D8 and D9 column\n",
    "    # As we almost sure it has connection with hours\n",
    "    df['D9_not_na'] = np.where(df['D9'].isna(),0,1)\n",
    "    df['D8_not_same_day'] = np.where(df['D8']>=1,1,0)\n",
    "    df['D8_D9_decimal_dist'] = df['D8'].fillna(0)-df['D8'].fillna(0).astype(int)\n",
    "    df['D8_D9_decimal_dist'] = ((df['D8_D9_decimal_dist']-df['D9'])**2)**0.5\n",
    "    df['D8'] = df['D8'].fillna(-1).astype(int)\n",
    "\n",
    "####### Values Normalization\n",
    "i_cols.remove('D1')\n",
    "i_cols.remove('D2')\n",
    "i_cols.remove('D9')\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "for df in [df_train, df_test]:\n",
    "    df = values_normalization(df, periods, i_cols)\n",
    "\n",
    "for col in ['D1','D2']:\n",
    "    for df in [df_train, df_test]:\n",
    "        df[col+'_scaled'] = df[col]/df_train[col].max()\n",
    "        \n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "df_train, df_test = frequency_encoding(df_train, df_test, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding the rest \n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n",
    "        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
    "        df_test[col] = le.transform(list(df_test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#why sort ??\n",
    "X_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT','TransactionID'], axis=1)\n",
    "y_train = df_train.sort_values('TransactionDT')['isFraud']\n",
    "\n",
    "X_test = df_test.drop(['TransactionDT'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-42c4db807580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m########################### Minification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'df_train.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'df_test.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mremove_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features_to_remove'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "########################### Minification\n",
    "df_train.to_pickle('df_train.pkl')\n",
    "df_test.to_pickle('df_test.pkl')\n",
    "\n",
    "remove_features = pd.DataFrame(remove_features, columns=['features_to_remove'])\n",
    "remove_features.to_pickle('remove_features.pkl')\n",
    "\n",
    "del df_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "##The following will carry out automated parameters optimisation for mainly accuray and overfitting related parameters based on Bayesian optimisation\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Those parameters are the optimised ones for 4 hours \n",
    "#small min_data, large min_leaves, small learning rate, gbdt. \n",
    "#https://www.kaggle.com/kyakovlev/ieee-gb-2-make-amount-useful-again\n",
    "best_param = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118712"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_train['rept_trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['DT'], axis=1)\n",
    "X_test = X_test.drop(['DT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionAmt\n",
      "ProductCD\n",
      "card1\n",
      "card2\n",
      "card3\n",
      "card4\n",
      "card5\n",
      "card6\n",
      "addr1\n",
      "addr2\n",
      "dist1\n",
      "P_emaildomain\n",
      "R_emaildomain\n",
      "C1\n",
      "C2\n",
      "C4\n",
      "C5\n",
      "C6\n",
      "C7\n",
      "C8\n",
      "C9\n",
      "C10\n",
      "C11\n",
      "C12\n",
      "C13\n",
      "C14\n",
      "D1\n",
      "D2\n",
      "D3\n",
      "D4\n",
      "D5\n",
      "D6\n",
      "D8\n",
      "D9\n",
      "D10\n",
      "D11\n",
      "D12\n",
      "D13\n",
      "D14\n",
      "D15\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "M7\n",
      "M8\n",
      "M9\n",
      "V3\n",
      "V4\n",
      "V5\n",
      "V6\n",
      "V7\n",
      "V8\n",
      "V9\n",
      "V10\n",
      "V11\n",
      "V12\n",
      "V13\n",
      "V17\n",
      "V19\n",
      "V20\n",
      "V29\n",
      "V30\n",
      "V33\n",
      "V34\n",
      "V35\n",
      "V36\n",
      "V37\n",
      "V38\n",
      "V40\n",
      "V44\n",
      "V45\n",
      "V46\n",
      "V47\n",
      "V48\n",
      "V49\n",
      "V51\n",
      "V52\n",
      "V53\n",
      "V54\n",
      "V56\n",
      "V58\n",
      "V59\n",
      "V60\n",
      "V61\n",
      "V62\n",
      "V63\n",
      "V64\n",
      "V69\n",
      "V70\n",
      "V71\n",
      "V72\n",
      "V73\n",
      "V74\n",
      "V75\n",
      "V76\n",
      "V78\n",
      "V80\n",
      "V81\n",
      "V82\n",
      "V83\n",
      "V84\n",
      "V85\n",
      "V87\n",
      "V90\n",
      "V91\n",
      "V92\n",
      "V93\n",
      "V94\n",
      "V95\n",
      "V96\n",
      "V97\n",
      "V99\n",
      "V100\n",
      "V126\n",
      "V127\n",
      "V128\n",
      "V130\n",
      "V131\n",
      "V138\n",
      "V139\n",
      "V140\n",
      "V143\n",
      "V145\n",
      "V146\n",
      "V147\n",
      "V149\n",
      "V150\n",
      "V151\n",
      "V152\n",
      "V154\n",
      "V156\n",
      "V158\n",
      "V159\n",
      "V160\n",
      "V161\n",
      "V162\n",
      "V163\n",
      "V164\n",
      "V165\n",
      "V166\n",
      "V167\n",
      "V169\n",
      "V170\n",
      "V171\n",
      "V172\n",
      "V173\n",
      "V175\n",
      "V176\n",
      "V177\n",
      "V178\n",
      "V180\n",
      "V182\n",
      "V184\n",
      "V187\n",
      "V188\n",
      "V189\n",
      "V195\n",
      "V197\n",
      "V200\n",
      "V201\n",
      "V202\n",
      "V203\n",
      "V204\n",
      "V205\n",
      "V206\n",
      "V207\n",
      "V208\n",
      "V209\n",
      "V210\n",
      "V212\n",
      "V213\n",
      "V214\n",
      "V215\n",
      "V216\n",
      "V217\n",
      "V219\n",
      "V220\n",
      "V221\n",
      "V222\n",
      "V223\n",
      "V224\n",
      "V225\n",
      "V226\n",
      "V227\n",
      "V228\n",
      "V229\n",
      "V231\n",
      "V233\n",
      "V234\n",
      "V238\n",
      "V239\n",
      "V242\n",
      "V243\n",
      "V244\n",
      "V245\n",
      "V246\n",
      "V247\n",
      "V249\n",
      "V251\n",
      "V253\n",
      "V256\n",
      "V257\n",
      "V258\n",
      "V259\n",
      "V261\n",
      "V262\n",
      "V263\n",
      "V264\n",
      "V265\n",
      "V266\n",
      "V267\n",
      "V268\n",
      "V270\n",
      "V271\n",
      "V272\n",
      "V273\n",
      "V274\n",
      "V275\n",
      "V276\n",
      "V277\n",
      "V278\n",
      "V279\n",
      "V280\n",
      "V282\n",
      "V283\n",
      "V285\n",
      "V287\n",
      "V288\n",
      "V289\n",
      "V291\n",
      "V292\n",
      "V294\n",
      "C_sum\n",
      "D_na\n",
      "M_na\n",
      "V_na\n",
      "id_01\n",
      "id_02\n",
      "id_03\n",
      "id_05\n",
      "id_06\n",
      "id_09\n",
      "id_11\n",
      "id_12\n",
      "id_13\n",
      "id_14\n",
      "id_15\n",
      "id_17\n",
      "id_19\n",
      "id_20\n",
      "id_30\n",
      "id_31\n",
      "id_32\n",
      "id_33\n",
      "id_36\n",
      "id_37\n",
      "id_38\n",
      "DeviceType\n",
      "DeviceInfo\n",
      "id_na\n",
      "device_name\n",
      "device_version\n",
      "OS_id_30\n",
      "version_id_30\n",
      "browser_id_31\n",
      "version_id_31\n",
      "screen_width\n",
      "screen_height\n",
      "had_id\n",
      "tot_na\n",
      "rept_trans\n",
      "DT_M\n",
      "DT_W\n",
      "DT_D\n",
      "DT_hour\n",
      "DT_day_week\n",
      "DT_day_month\n",
      "is_december\n",
      "is_holiday\n",
      "DT_M_total\n",
      "DT_W_total\n",
      "DT_D_total\n",
      "uid\n",
      "uid2\n",
      "uid3\n",
      "uid4\n",
      "uid5\n",
      "card1_fq_enc\n",
      "card2_fq_enc\n",
      "card3_fq_enc\n",
      "card5_fq_enc\n",
      "uid_fq_enc\n",
      "uid2_fq_enc\n",
      "uid3_fq_enc\n",
      "uid4_fq_enc\n",
      "uid5_fq_enc\n",
      "TransactionAmt_decimal\n",
      "Transaction_day_of_week\n",
      "Transaction_hour\n",
      "id_02__id_20\n",
      "id_02__D8\n",
      "D11__DeviceInfo\n",
      "DeviceInfo__P_emaildomain\n",
      "card2__dist1\n",
      "card1__card5\n",
      "card2__id_20\n",
      "card1__P_emaildomain\n",
      "addr1__card1\n",
      "card1_count_full\n",
      "card2_count_full\n",
      "card3_count_full\n",
      "card4_count_full\n",
      "card5_count_full\n",
      "card6_count_full\n",
      "id_36_count_full\n",
      "id_01_count_dist\n",
      "id_31_count_dist\n",
      "id_33_count_dist\n",
      "id_36_count_dist\n",
      "card1_target_enc\n",
      "card2_target_enc\n",
      "addr1_target_enc\n",
      "addr1__card1_target_enc\n",
      "card1__card5_target_enc\n",
      "card1__P_emaildomain_target_enc\n",
      "uid_D1_mean\n",
      "uid_D1_std\n",
      "uid2_D1_mean\n",
      "uid2_D1_std\n",
      "uid3_D1_mean\n",
      "uid3_D1_std\n",
      "uid4_D1_mean\n",
      "uid4_D1_std\n",
      "uid5_D1_mean\n",
      "uid5_D1_std\n"
     ]
    }
   ],
   "source": [
    "for i in X_train.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.94676\tvalid_1's auc: 0.857529\n",
      "[20]\ttraining's auc: 0.957884\tvalid_1's auc: 0.863769\n",
      "[30]\ttraining's auc: 0.964813\tvalid_1's auc: 0.870379\n",
      "[40]\ttraining's auc: 0.967446\tvalid_1's auc: 0.874382\n",
      "[50]\ttraining's auc: 0.971072\tvalid_1's auc: 0.876252\n",
      "[60]\ttraining's auc: 0.973252\tvalid_1's auc: 0.877216\n",
      "[70]\ttraining's auc: 0.975387\tvalid_1's auc: 0.878521\n",
      "[80]\ttraining's auc: 0.977551\tvalid_1's auc: 0.878609\n",
      "[90]\ttraining's auc: 0.979663\tvalid_1's auc: 0.879456\n",
      "[100]\ttraining's auc: 0.981077\tvalid_1's auc: 0.880524\n",
      "[110]\ttraining's auc: 0.982552\tvalid_1's auc: 0.881134\n",
      "[120]\ttraining's auc: 0.983895\tvalid_1's auc: 0.88187\n",
      "[130]\ttraining's auc: 0.984839\tvalid_1's auc: 0.882216\n",
      "[140]\ttraining's auc: 0.98579\tvalid_1's auc: 0.882734\n",
      "[150]\ttraining's auc: 0.986823\tvalid_1's auc: 0.88328\n",
      "[160]\ttraining's auc: 0.987801\tvalid_1's auc: 0.884077\n",
      "[170]\ttraining's auc: 0.988599\tvalid_1's auc: 0.884847\n",
      "[180]\ttraining's auc: 0.989402\tvalid_1's auc: 0.88551\n",
      "[190]\ttraining's auc: 0.990084\tvalid_1's auc: 0.885912\n",
      "[200]\ttraining's auc: 0.990756\tvalid_1's auc: 0.886904\n",
      "[210]\ttraining's auc: 0.991379\tvalid_1's auc: 0.887466\n",
      "[220]\ttraining's auc: 0.99188\tvalid_1's auc: 0.887573\n",
      "[230]\ttraining's auc: 0.99242\tvalid_1's auc: 0.887732\n",
      "[240]\ttraining's auc: 0.992929\tvalid_1's auc: 0.888227\n",
      "[250]\ttraining's auc: 0.993419\tvalid_1's auc: 0.888562\n",
      "[260]\ttraining's auc: 0.993805\tvalid_1's auc: 0.888779\n",
      "[270]\ttraining's auc: 0.994223\tvalid_1's auc: 0.889158\n",
      "[280]\ttraining's auc: 0.994611\tvalid_1's auc: 0.889603\n",
      "[290]\ttraining's auc: 0.99496\tvalid_1's auc: 0.889808\n",
      "[300]\ttraining's auc: 0.995311\tvalid_1's auc: 0.890091\n",
      "[310]\ttraining's auc: 0.995632\tvalid_1's auc: 0.890314\n",
      "[320]\ttraining's auc: 0.995921\tvalid_1's auc: 0.890566\n",
      "[330]\ttraining's auc: 0.996191\tvalid_1's auc: 0.890628\n",
      "[340]\ttraining's auc: 0.996457\tvalid_1's auc: 0.890752\n",
      "[350]\ttraining's auc: 0.996712\tvalid_1's auc: 0.890908\n",
      "[360]\ttraining's auc: 0.996928\tvalid_1's auc: 0.891207\n",
      "[370]\ttraining's auc: 0.997151\tvalid_1's auc: 0.891431\n",
      "[380]\ttraining's auc: 0.997348\tvalid_1's auc: 0.891418\n",
      "[390]\ttraining's auc: 0.997555\tvalid_1's auc: 0.89143\n",
      "[400]\ttraining's auc: 0.997722\tvalid_1's auc: 0.891657\n",
      "[410]\ttraining's auc: 0.997877\tvalid_1's auc: 0.891607\n",
      "[420]\ttraining's auc: 0.998035\tvalid_1's auc: 0.891745\n",
      "[430]\ttraining's auc: 0.998179\tvalid_1's auc: 0.891898\n",
      "[440]\ttraining's auc: 0.998317\tvalid_1's auc: 0.891844\n",
      "[450]\ttraining's auc: 0.998435\tvalid_1's auc: 0.891767\n",
      "[460]\ttraining's auc: 0.998557\tvalid_1's auc: 0.891715\n",
      "[470]\ttraining's auc: 0.998656\tvalid_1's auc: 0.89192\n",
      "[480]\ttraining's auc: 0.998749\tvalid_1's auc: 0.892205\n",
      "[490]\ttraining's auc: 0.998832\tvalid_1's auc: 0.892281\n",
      "[500]\ttraining's auc: 0.998912\tvalid_1's auc: 0.89249\n",
      "[510]\ttraining's auc: 0.998981\tvalid_1's auc: 0.892413\n",
      "[520]\ttraining's auc: 0.99906\tvalid_1's auc: 0.892729\n",
      "[530]\ttraining's auc: 0.999123\tvalid_1's auc: 0.892836\n",
      "[540]\ttraining's auc: 0.999182\tvalid_1's auc: 0.892733\n",
      "[550]\ttraining's auc: 0.99924\tvalid_1's auc: 0.89278\n",
      "[560]\ttraining's auc: 0.999299\tvalid_1's auc: 0.892902\n",
      "[570]\ttraining's auc: 0.999346\tvalid_1's auc: 0.892887\n",
      "[580]\ttraining's auc: 0.999393\tvalid_1's auc: 0.892945\n",
      "[590]\ttraining's auc: 0.999443\tvalid_1's auc: 0.89309\n",
      "[600]\ttraining's auc: 0.999482\tvalid_1's auc: 0.893247\n",
      "[610]\ttraining's auc: 0.999518\tvalid_1's auc: 0.893363\n",
      "[620]\ttraining's auc: 0.999552\tvalid_1's auc: 0.893377\n",
      "[630]\ttraining's auc: 0.999582\tvalid_1's auc: 0.893482\n",
      "[640]\ttraining's auc: 0.999614\tvalid_1's auc: 0.89363\n",
      "[650]\ttraining's auc: 0.999644\tvalid_1's auc: 0.893725\n",
      "[660]\ttraining's auc: 0.999667\tvalid_1's auc: 0.893858\n",
      "[670]\ttraining's auc: 0.999693\tvalid_1's auc: 0.894096\n",
      "[680]\ttraining's auc: 0.999717\tvalid_1's auc: 0.894163\n",
      "[690]\ttraining's auc: 0.999738\tvalid_1's auc: 0.894213\n",
      "[700]\ttraining's auc: 0.999758\tvalid_1's auc: 0.894172\n",
      "[710]\ttraining's auc: 0.999776\tvalid_1's auc: 0.894321\n",
      "[720]\ttraining's auc: 0.999794\tvalid_1's auc: 0.894461\n",
      "[730]\ttraining's auc: 0.999809\tvalid_1's auc: 0.89471\n",
      "[740]\ttraining's auc: 0.999822\tvalid_1's auc: 0.894729\n",
      "[750]\ttraining's auc: 0.999836\tvalid_1's auc: 0.894774\n",
      "[760]\ttraining's auc: 0.999849\tvalid_1's auc: 0.894841\n",
      "[770]\ttraining's auc: 0.999861\tvalid_1's auc: 0.89502\n",
      "[780]\ttraining's auc: 0.999872\tvalid_1's auc: 0.89515\n",
      "[790]\ttraining's auc: 0.999881\tvalid_1's auc: 0.895232\n",
      "[800]\ttraining's auc: 0.999891\tvalid_1's auc: 0.895172\n",
      "[810]\ttraining's auc: 0.9999\tvalid_1's auc: 0.895316\n",
      "[820]\ttraining's auc: 0.999908\tvalid_1's auc: 0.89548\n",
      "[830]\ttraining's auc: 0.999915\tvalid_1's auc: 0.895679\n",
      "[840]\ttraining's auc: 0.999922\tvalid_1's auc: 0.895811\n",
      "[850]\ttraining's auc: 0.999929\tvalid_1's auc: 0.896023\n",
      "[860]\ttraining's auc: 0.999935\tvalid_1's auc: 0.89612\n",
      "[870]\ttraining's auc: 0.999941\tvalid_1's auc: 0.896199\n",
      "[880]\ttraining's auc: 0.999946\tvalid_1's auc: 0.89618\n",
      "[890]\ttraining's auc: 0.999951\tvalid_1's auc: 0.896248\n",
      "[900]\ttraining's auc: 0.999955\tvalid_1's auc: 0.896396\n",
      "[910]\ttraining's auc: 0.999959\tvalid_1's auc: 0.89669\n",
      "[920]\ttraining's auc: 0.999962\tvalid_1's auc: 0.896718\n",
      "[930]\ttraining's auc: 0.999965\tvalid_1's auc: 0.896849\n",
      "[940]\ttraining's auc: 0.999968\tvalid_1's auc: 0.896886\n",
      "[950]\ttraining's auc: 0.999971\tvalid_1's auc: 0.896933\n",
      "[960]\ttraining's auc: 0.999973\tvalid_1's auc: 0.897185\n",
      "[970]\ttraining's auc: 0.999975\tvalid_1's auc: 0.897285\n",
      "[980]\ttraining's auc: 0.999977\tvalid_1's auc: 0.897438\n",
      "[990]\ttraining's auc: 0.99998\tvalid_1's auc: 0.897539\n",
      "[1000]\ttraining's auc: 0.999981\tvalid_1's auc: 0.897735\n",
      "[1010]\ttraining's auc: 0.999983\tvalid_1's auc: 0.897911\n",
      "[1020]\ttraining's auc: 0.999985\tvalid_1's auc: 0.898023\n",
      "[1030]\ttraining's auc: 0.999986\tvalid_1's auc: 0.898198\n",
      "[1040]\ttraining's auc: 0.999987\tvalid_1's auc: 0.898315\n",
      "[1050]\ttraining's auc: 0.999988\tvalid_1's auc: 0.898553\n",
      "[1060]\ttraining's auc: 0.99999\tvalid_1's auc: 0.898724\n",
      "[1070]\ttraining's auc: 0.999991\tvalid_1's auc: 0.89877\n",
      "[1080]\ttraining's auc: 0.999992\tvalid_1's auc: 0.898825\n",
      "[1090]\ttraining's auc: 0.999992\tvalid_1's auc: 0.898885\n",
      "[1100]\ttraining's auc: 0.999993\tvalid_1's auc: 0.899037\n",
      "[1110]\ttraining's auc: 0.999994\tvalid_1's auc: 0.899138\n",
      "[1120]\ttraining's auc: 0.999994\tvalid_1's auc: 0.89925\n",
      "[1130]\ttraining's auc: 0.999995\tvalid_1's auc: 0.899384\n",
      "[1140]\ttraining's auc: 0.999995\tvalid_1's auc: 0.899592\n",
      "[1150]\ttraining's auc: 0.999996\tvalid_1's auc: 0.899734\n",
      "[1160]\ttraining's auc: 0.999996\tvalid_1's auc: 0.899838\n",
      "[1170]\ttraining's auc: 0.999997\tvalid_1's auc: 0.900031\n",
      "[1180]\ttraining's auc: 0.999997\tvalid_1's auc: 0.900153\n",
      "[1190]\ttraining's auc: 0.999997\tvalid_1's auc: 0.900187\n",
      "[1200]\ttraining's auc: 0.999998\tvalid_1's auc: 0.900291\n",
      "[1210]\ttraining's auc: 0.999998\tvalid_1's auc: 0.900496\n",
      "[1220]\ttraining's auc: 0.999998\tvalid_1's auc: 0.900547\n",
      "[1230]\ttraining's auc: 0.999998\tvalid_1's auc: 0.900615\n",
      "[1240]\ttraining's auc: 0.999999\tvalid_1's auc: 0.900518\n",
      "[1250]\ttraining's auc: 0.999999\tvalid_1's auc: 0.900683\n",
      "[1260]\ttraining's auc: 0.999999\tvalid_1's auc: 0.90081\n",
      "[1270]\ttraining's auc: 0.999999\tvalid_1's auc: 0.901016\n",
      "[1280]\ttraining's auc: 0.999999\tvalid_1's auc: 0.901193\n",
      "[1290]\ttraining's auc: 0.999999\tvalid_1's auc: 0.901343\n",
      "[1300]\ttraining's auc: 0.999999\tvalid_1's auc: 0.90142\n",
      "[1310]\ttraining's auc: 0.999999\tvalid_1's auc: 0.901567\n",
      "[1320]\ttraining's auc: 0.999999\tvalid_1's auc: 0.901663\n",
      "[1330]\ttraining's auc: 0.999999\tvalid_1's auc: 0.901822\n",
      "[1340]\ttraining's auc: 1\tvalid_1's auc: 0.901997\n",
      "[1350]\ttraining's auc: 1\tvalid_1's auc: 0.902028\n",
      "[1360]\ttraining's auc: 1\tvalid_1's auc: 0.902195\n",
      "[1370]\ttraining's auc: 1\tvalid_1's auc: 0.902387\n",
      "[1380]\ttraining's auc: 1\tvalid_1's auc: 0.902418\n",
      "[1390]\ttraining's auc: 1\tvalid_1's auc: 0.902554\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.902571\n",
      "[1410]\ttraining's auc: 1\tvalid_1's auc: 0.902648\n",
      "[1420]\ttraining's auc: 1\tvalid_1's auc: 0.90272\n",
      "[1430]\ttraining's auc: 1\tvalid_1's auc: 0.9028\n",
      "[1440]\ttraining's auc: 1\tvalid_1's auc: 0.902946\n",
      "[1450]\ttraining's auc: 1\tvalid_1's auc: 0.903028\n",
      "[1460]\ttraining's auc: 1\tvalid_1's auc: 0.903108\n",
      "[1470]\ttraining's auc: 1\tvalid_1's auc: 0.903242\n",
      "[1480]\ttraining's auc: 1\tvalid_1's auc: 0.903356\n",
      "[1490]\ttraining's auc: 1\tvalid_1's auc: 0.903505\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.903665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1510]\ttraining's auc: 1\tvalid_1's auc: 0.903827\n",
      "[1520]\ttraining's auc: 1\tvalid_1's auc: 0.903805\n",
      "[1530]\ttraining's auc: 1\tvalid_1's auc: 0.903809\n",
      "[1540]\ttraining's auc: 1\tvalid_1's auc: 0.903953\n",
      "[1550]\ttraining's auc: 1\tvalid_1's auc: 0.903942\n",
      "[1560]\ttraining's auc: 1\tvalid_1's auc: 0.903995\n",
      "[1570]\ttraining's auc: 1\tvalid_1's auc: 0.904126\n",
      "[1580]\ttraining's auc: 1\tvalid_1's auc: 0.904211\n",
      "[1590]\ttraining's auc: 1\tvalid_1's auc: 0.904285\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.90432\n",
      "[1610]\ttraining's auc: 1\tvalid_1's auc: 0.904433\n",
      "[1620]\ttraining's auc: 1\tvalid_1's auc: 0.904534\n",
      "[1630]\ttraining's auc: 1\tvalid_1's auc: 0.904661\n",
      "[1640]\ttraining's auc: 1\tvalid_1's auc: 0.904751\n",
      "[1650]\ttraining's auc: 1\tvalid_1's auc: 0.904873\n",
      "[1660]\ttraining's auc: 1\tvalid_1's auc: 0.904922\n",
      "[1670]\ttraining's auc: 1\tvalid_1's auc: 0.905077\n",
      "[1680]\ttraining's auc: 1\tvalid_1's auc: 0.905158\n",
      "[1690]\ttraining's auc: 1\tvalid_1's auc: 0.905242\n",
      "[1700]\ttraining's auc: 1\tvalid_1's auc: 0.905383\n",
      "[1710]\ttraining's auc: 1\tvalid_1's auc: 0.9055\n",
      "[1720]\ttraining's auc: 1\tvalid_1's auc: 0.905581\n",
      "[1730]\ttraining's auc: 1\tvalid_1's auc: 0.90567\n",
      "[1740]\ttraining's auc: 1\tvalid_1's auc: 0.905888\n",
      "[1750]\ttraining's auc: 1\tvalid_1's auc: 0.906001\n",
      "[1760]\ttraining's auc: 1\tvalid_1's auc: 0.906111\n",
      "[1770]\ttraining's auc: 1\tvalid_1's auc: 0.906125\n",
      "[1780]\ttraining's auc: 1\tvalid_1's auc: 0.906222\n",
      "[1790]\ttraining's auc: 1\tvalid_1's auc: 0.90619\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.90633\n",
      "[1810]\ttraining's auc: 1\tvalid_1's auc: 0.906501\n",
      "[1820]\ttraining's auc: 1\tvalid_1's auc: 0.906518\n",
      "[1830]\ttraining's auc: 1\tvalid_1's auc: 0.906634\n",
      "[1840]\ttraining's auc: 1\tvalid_1's auc: 0.906694\n",
      "[1850]\ttraining's auc: 1\tvalid_1's auc: 0.906728\n",
      "[1860]\ttraining's auc: 1\tvalid_1's auc: 0.906847\n",
      "[1870]\ttraining's auc: 1\tvalid_1's auc: 0.906842\n",
      "[1880]\ttraining's auc: 1\tvalid_1's auc: 0.906987\n",
      "[1890]\ttraining's auc: 1\tvalid_1's auc: 0.907023\n",
      "[1900]\ttraining's auc: 1\tvalid_1's auc: 0.907079\n",
      "[1910]\ttraining's auc: 1\tvalid_1's auc: 0.907155\n",
      "[1920]\ttraining's auc: 1\tvalid_1's auc: 0.90722\n",
      "Early stopping, best iteration is:\n",
      "[1827]\ttraining's auc: 1\tvalid_1's auc: 0.906632\n",
      "Fold 1 | AUC: 0.9066286734914216\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.946328\tvalid_1's auc: 0.895846\n",
      "[20]\ttraining's auc: 0.958044\tvalid_1's auc: 0.901514\n",
      "[30]\ttraining's auc: 0.964201\tvalid_1's auc: 0.905274\n",
      "[40]\ttraining's auc: 0.96695\tvalid_1's auc: 0.905498\n",
      "[50]\ttraining's auc: 0.969672\tvalid_1's auc: 0.906589\n",
      "[60]\ttraining's auc: 0.971879\tvalid_1's auc: 0.908953\n",
      "[70]\ttraining's auc: 0.974569\tvalid_1's auc: 0.910446\n",
      "[80]\ttraining's auc: 0.977257\tvalid_1's auc: 0.912026\n",
      "[90]\ttraining's auc: 0.979419\tvalid_1's auc: 0.913282\n",
      "[100]\ttraining's auc: 0.980858\tvalid_1's auc: 0.914247\n",
      "[110]\ttraining's auc: 0.98244\tvalid_1's auc: 0.914778\n",
      "[120]\ttraining's auc: 0.983656\tvalid_1's auc: 0.91568\n",
      "[130]\ttraining's auc: 0.984774\tvalid_1's auc: 0.916214\n",
      "[140]\ttraining's auc: 0.985897\tvalid_1's auc: 0.917111\n",
      "[150]\ttraining's auc: 0.987239\tvalid_1's auc: 0.917723\n",
      "[160]\ttraining's auc: 0.988054\tvalid_1's auc: 0.918287\n",
      "[170]\ttraining's auc: 0.988916\tvalid_1's auc: 0.918616\n",
      "[180]\ttraining's auc: 0.989798\tvalid_1's auc: 0.919052\n",
      "[190]\ttraining's auc: 0.990653\tvalid_1's auc: 0.919661\n",
      "[200]\ttraining's auc: 0.991284\tvalid_1's auc: 0.920002\n",
      "[210]\ttraining's auc: 0.991922\tvalid_1's auc: 0.920323\n",
      "[220]\ttraining's auc: 0.992522\tvalid_1's auc: 0.920507\n",
      "[230]\ttraining's auc: 0.993079\tvalid_1's auc: 0.920659\n",
      "[240]\ttraining's auc: 0.993661\tvalid_1's auc: 0.921016\n",
      "[250]\ttraining's auc: 0.994159\tvalid_1's auc: 0.921398\n",
      "[260]\ttraining's auc: 0.994582\tvalid_1's auc: 0.921562\n",
      "[270]\ttraining's auc: 0.994958\tvalid_1's auc: 0.92176\n",
      "[280]\ttraining's auc: 0.995326\tvalid_1's auc: 0.921953\n",
      "[290]\ttraining's auc: 0.995672\tvalid_1's auc: 0.922171\n",
      "[300]\ttraining's auc: 0.995998\tvalid_1's auc: 0.922333\n",
      "[310]\ttraining's auc: 0.996282\tvalid_1's auc: 0.922477\n",
      "[320]\ttraining's auc: 0.996559\tvalid_1's auc: 0.922589\n",
      "[330]\ttraining's auc: 0.996826\tvalid_1's auc: 0.922558\n",
      "[340]\ttraining's auc: 0.997067\tvalid_1's auc: 0.922485\n",
      "[350]\ttraining's auc: 0.997289\tvalid_1's auc: 0.922353\n",
      "[360]\ttraining's auc: 0.997497\tvalid_1's auc: 0.922525\n",
      "[370]\ttraining's auc: 0.997696\tvalid_1's auc: 0.922515\n",
      "[380]\ttraining's auc: 0.997878\tvalid_1's auc: 0.922637\n",
      "[390]\ttraining's auc: 0.998057\tvalid_1's auc: 0.922769\n",
      "[400]\ttraining's auc: 0.998204\tvalid_1's auc: 0.922788\n",
      "[410]\ttraining's auc: 0.998333\tvalid_1's auc: 0.922837\n",
      "[420]\ttraining's auc: 0.998462\tvalid_1's auc: 0.922872\n",
      "[430]\ttraining's auc: 0.998572\tvalid_1's auc: 0.922851\n",
      "[440]\ttraining's auc: 0.998684\tvalid_1's auc: 0.922778\n",
      "[450]\ttraining's auc: 0.998786\tvalid_1's auc: 0.92262\n",
      "[460]\ttraining's auc: 0.998889\tvalid_1's auc: 0.922699\n",
      "[470]\ttraining's auc: 0.99897\tvalid_1's auc: 0.922752\n",
      "[480]\ttraining's auc: 0.999045\tvalid_1's auc: 0.922802\n",
      "[490]\ttraining's auc: 0.999116\tvalid_1's auc: 0.922774\n",
      "[500]\ttraining's auc: 0.999195\tvalid_1's auc: 0.922985\n",
      "[510]\ttraining's auc: 0.999256\tvalid_1's auc: 0.922822\n",
      "[520]\ttraining's auc: 0.999317\tvalid_1's auc: 0.922816\n",
      "[530]\ttraining's auc: 0.999365\tvalid_1's auc: 0.922829\n",
      "[540]\ttraining's auc: 0.999412\tvalid_1's auc: 0.922661\n",
      "[550]\ttraining's auc: 0.999455\tvalid_1's auc: 0.922812\n",
      "[560]\ttraining's auc: 0.999497\tvalid_1's auc: 0.92286\n",
      "[570]\ttraining's auc: 0.999541\tvalid_1's auc: 0.923071\n",
      "[580]\ttraining's auc: 0.999577\tvalid_1's auc: 0.92326\n",
      "[590]\ttraining's auc: 0.999608\tvalid_1's auc: 0.923312\n",
      "[600]\ttraining's auc: 0.999641\tvalid_1's auc: 0.923292\n",
      "[610]\ttraining's auc: 0.999672\tvalid_1's auc: 0.923486\n",
      "[620]\ttraining's auc: 0.999698\tvalid_1's auc: 0.923448\n",
      "[630]\ttraining's auc: 0.999722\tvalid_1's auc: 0.923547\n",
      "[640]\ttraining's auc: 0.999745\tvalid_1's auc: 0.923744\n",
      "[650]\ttraining's auc: 0.999768\tvalid_1's auc: 0.92375\n",
      "[660]\ttraining's auc: 0.999786\tvalid_1's auc: 0.923701\n",
      "[670]\ttraining's auc: 0.999802\tvalid_1's auc: 0.923886\n",
      "[680]\ttraining's auc: 0.999818\tvalid_1's auc: 0.923911\n",
      "[690]\ttraining's auc: 0.999834\tvalid_1's auc: 0.924044\n",
      "[700]\ttraining's auc: 0.999847\tvalid_1's auc: 0.924194\n",
      "[710]\ttraining's auc: 0.999859\tvalid_1's auc: 0.924229\n",
      "[720]\ttraining's auc: 0.999871\tvalid_1's auc: 0.92435\n",
      "[730]\ttraining's auc: 0.999882\tvalid_1's auc: 0.924447\n",
      "[740]\ttraining's auc: 0.999892\tvalid_1's auc: 0.924392\n",
      "[750]\ttraining's auc: 0.999901\tvalid_1's auc: 0.924574\n",
      "[760]\ttraining's auc: 0.99991\tvalid_1's auc: 0.924708\n",
      "[770]\ttraining's auc: 0.999919\tvalid_1's auc: 0.924786\n",
      "[780]\ttraining's auc: 0.999926\tvalid_1's auc: 0.924895\n",
      "[790]\ttraining's auc: 0.999932\tvalid_1's auc: 0.924958\n",
      "[800]\ttraining's auc: 0.999938\tvalid_1's auc: 0.925098\n",
      "[810]\ttraining's auc: 0.999943\tvalid_1's auc: 0.925116\n",
      "[820]\ttraining's auc: 0.999947\tvalid_1's auc: 0.925092\n",
      "[830]\ttraining's auc: 0.999952\tvalid_1's auc: 0.925147\n",
      "[840]\ttraining's auc: 0.999956\tvalid_1's auc: 0.925225\n",
      "[850]\ttraining's auc: 0.999961\tvalid_1's auc: 0.925213\n",
      "[860]\ttraining's auc: 0.999965\tvalid_1's auc: 0.92536\n",
      "[870]\ttraining's auc: 0.999968\tvalid_1's auc: 0.92544\n",
      "[880]\ttraining's auc: 0.999971\tvalid_1's auc: 0.925479\n",
      "[890]\ttraining's auc: 0.999974\tvalid_1's auc: 0.925577\n",
      "[900]\ttraining's auc: 0.999976\tvalid_1's auc: 0.925554\n",
      "[910]\ttraining's auc: 0.999978\tvalid_1's auc: 0.925601\n",
      "[920]\ttraining's auc: 0.99998\tvalid_1's auc: 0.925612\n",
      "[930]\ttraining's auc: 0.999982\tvalid_1's auc: 0.925642\n",
      "[940]\ttraining's auc: 0.999984\tvalid_1's auc: 0.925741\n",
      "[950]\ttraining's auc: 0.999986\tvalid_1's auc: 0.925774\n",
      "[960]\ttraining's auc: 0.999987\tvalid_1's auc: 0.925834\n",
      "[970]\ttraining's auc: 0.999989\tvalid_1's auc: 0.925968\n",
      "[980]\ttraining's auc: 0.99999\tvalid_1's auc: 0.92603\n",
      "[990]\ttraining's auc: 0.999991\tvalid_1's auc: 0.926061\n",
      "[1000]\ttraining's auc: 0.999992\tvalid_1's auc: 0.926092\n",
      "[1010]\ttraining's auc: 0.999993\tvalid_1's auc: 0.926102\n",
      "[1020]\ttraining's auc: 0.999994\tvalid_1's auc: 0.926183\n",
      "[1030]\ttraining's auc: 0.999994\tvalid_1's auc: 0.926236\n",
      "[1040]\ttraining's auc: 0.999995\tvalid_1's auc: 0.92629\n",
      "[1050]\ttraining's auc: 0.999996\tvalid_1's auc: 0.926346\n",
      "[1060]\ttraining's auc: 0.999996\tvalid_1's auc: 0.926409\n",
      "[1070]\ttraining's auc: 0.999996\tvalid_1's auc: 0.926455\n",
      "[1080]\ttraining's auc: 0.999997\tvalid_1's auc: 0.926471\n",
      "[1090]\ttraining's auc: 0.999997\tvalid_1's auc: 0.926587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttraining's auc: 0.999998\tvalid_1's auc: 0.926647\n",
      "[1110]\ttraining's auc: 0.999998\tvalid_1's auc: 0.926786\n",
      "[1120]\ttraining's auc: 0.999998\tvalid_1's auc: 0.926864\n",
      "[1130]\ttraining's auc: 0.999998\tvalid_1's auc: 0.926905\n",
      "[1140]\ttraining's auc: 0.999999\tvalid_1's auc: 0.926919\n",
      "[1150]\ttraining's auc: 0.999999\tvalid_1's auc: 0.926942\n",
      "[1160]\ttraining's auc: 0.999999\tvalid_1's auc: 0.927057\n",
      "[1170]\ttraining's auc: 0.999999\tvalid_1's auc: 0.927088\n",
      "[1180]\ttraining's auc: 0.999999\tvalid_1's auc: 0.927096\n",
      "[1190]\ttraining's auc: 0.999999\tvalid_1's auc: 0.927104\n",
      "[1200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.927148\n",
      "[1210]\ttraining's auc: 0.999999\tvalid_1's auc: 0.927277\n",
      "[1220]\ttraining's auc: 1\tvalid_1's auc: 0.927251\n",
      "[1230]\ttraining's auc: 1\tvalid_1's auc: 0.927263\n",
      "[1240]\ttraining's auc: 1\tvalid_1's auc: 0.927326\n",
      "[1250]\ttraining's auc: 1\tvalid_1's auc: 0.927393\n",
      "[1260]\ttraining's auc: 1\tvalid_1's auc: 0.927455\n",
      "[1270]\ttraining's auc: 1\tvalid_1's auc: 0.927458\n",
      "[1280]\ttraining's auc: 1\tvalid_1's auc: 0.927492\n",
      "[1290]\ttraining's auc: 1\tvalid_1's auc: 0.927527\n",
      "[1300]\ttraining's auc: 1\tvalid_1's auc: 0.927627\n",
      "[1310]\ttraining's auc: 1\tvalid_1's auc: 0.927701\n",
      "[1320]\ttraining's auc: 1\tvalid_1's auc: 0.927745\n",
      "[1330]\ttraining's auc: 1\tvalid_1's auc: 0.927825\n",
      "[1340]\ttraining's auc: 1\tvalid_1's auc: 0.927833\n",
      "[1350]\ttraining's auc: 1\tvalid_1's auc: 0.927892\n",
      "[1360]\ttraining's auc: 1\tvalid_1's auc: 0.927944\n",
      "[1370]\ttraining's auc: 1\tvalid_1's auc: 0.927902\n",
      "[1380]\ttraining's auc: 1\tvalid_1's auc: 0.927981\n",
      "[1390]\ttraining's auc: 1\tvalid_1's auc: 0.928073\n",
      "[1400]\ttraining's auc: 1\tvalid_1's auc: 0.928093\n",
      "[1410]\ttraining's auc: 1\tvalid_1's auc: 0.928099\n",
      "[1420]\ttraining's auc: 1\tvalid_1's auc: 0.928113\n",
      "[1430]\ttraining's auc: 1\tvalid_1's auc: 0.92816\n",
      "[1440]\ttraining's auc: 1\tvalid_1's auc: 0.928217\n",
      "[1450]\ttraining's auc: 1\tvalid_1's auc: 0.928273\n",
      "[1460]\ttraining's auc: 1\tvalid_1's auc: 0.928246\n",
      "[1470]\ttraining's auc: 1\tvalid_1's auc: 0.928273\n",
      "[1480]\ttraining's auc: 1\tvalid_1's auc: 0.928293\n",
      "[1490]\ttraining's auc: 1\tvalid_1's auc: 0.928364\n",
      "[1500]\ttraining's auc: 1\tvalid_1's auc: 0.928433\n",
      "[1510]\ttraining's auc: 1\tvalid_1's auc: 0.928496\n",
      "[1520]\ttraining's auc: 1\tvalid_1's auc: 0.92856\n",
      "[1530]\ttraining's auc: 1\tvalid_1's auc: 0.92856\n",
      "[1540]\ttraining's auc: 1\tvalid_1's auc: 0.928554\n",
      "[1550]\ttraining's auc: 1\tvalid_1's auc: 0.928577\n",
      "[1560]\ttraining's auc: 1\tvalid_1's auc: 0.928714\n",
      "[1570]\ttraining's auc: 1\tvalid_1's auc: 0.928677\n",
      "[1580]\ttraining's auc: 1\tvalid_1's auc: 0.928672\n",
      "[1590]\ttraining's auc: 1\tvalid_1's auc: 0.928663\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.92865\n",
      "[1610]\ttraining's auc: 1\tvalid_1's auc: 0.928641\n",
      "[1620]\ttraining's auc: 1\tvalid_1's auc: 0.928661\n",
      "[1630]\ttraining's auc: 1\tvalid_1's auc: 0.928709\n",
      "[1640]\ttraining's auc: 1\tvalid_1's auc: 0.928735\n",
      "[1650]\ttraining's auc: 1\tvalid_1's auc: 0.928795\n",
      "[1660]\ttraining's auc: 1\tvalid_1's auc: 0.928803\n",
      "[1670]\ttraining's auc: 1\tvalid_1's auc: 0.928819\n",
      "[1680]\ttraining's auc: 1\tvalid_1's auc: 0.928859\n",
      "[1690]\ttraining's auc: 1\tvalid_1's auc: 0.928851\n",
      "[1700]\ttraining's auc: 1\tvalid_1's auc: 0.928869\n",
      "[1710]\ttraining's auc: 1\tvalid_1's auc: 0.928879\n",
      "[1720]\ttraining's auc: 1\tvalid_1's auc: 0.928877\n",
      "[1730]\ttraining's auc: 1\tvalid_1's auc: 0.928898\n",
      "Early stopping, best iteration is:\n",
      "[1633]\ttraining's auc: 1\tvalid_1's auc: 0.92872\n",
      "Fold 2 | AUC: 0.9287188185113265\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.946324\tvalid_1's auc: 0.893597\n",
      "[20]\ttraining's auc: 0.959072\tvalid_1's auc: 0.903526\n",
      "[30]\ttraining's auc: 0.964393\tvalid_1's auc: 0.907363\n",
      "[40]\ttraining's auc: 0.967061\tvalid_1's auc: 0.909034\n",
      "[50]\ttraining's auc: 0.969636\tvalid_1's auc: 0.910023\n",
      "[60]\ttraining's auc: 0.972325\tvalid_1's auc: 0.911635\n",
      "[70]\ttraining's auc: 0.975192\tvalid_1's auc: 0.912633\n",
      "[80]\ttraining's auc: 0.977742\tvalid_1's auc: 0.913541\n",
      "[90]\ttraining's auc: 0.979518\tvalid_1's auc: 0.914521\n",
      "[100]\ttraining's auc: 0.98118\tvalid_1's auc: 0.914854\n",
      "[110]\ttraining's auc: 0.982692\tvalid_1's auc: 0.915381\n",
      "[120]\ttraining's auc: 0.983886\tvalid_1's auc: 0.915787\n",
      "[130]\ttraining's auc: 0.984923\tvalid_1's auc: 0.916159\n",
      "[140]\ttraining's auc: 0.985904\tvalid_1's auc: 0.916482\n",
      "[150]\ttraining's auc: 0.986877\tvalid_1's auc: 0.91679\n",
      "[160]\ttraining's auc: 0.987851\tvalid_1's auc: 0.917453\n",
      "[170]\ttraining's auc: 0.988724\tvalid_1's auc: 0.917468\n",
      "[180]\ttraining's auc: 0.989695\tvalid_1's auc: 0.91806\n",
      "[190]\ttraining's auc: 0.990523\tvalid_1's auc: 0.918525\n",
      "[200]\ttraining's auc: 0.991206\tvalid_1's auc: 0.918699\n",
      "[210]\ttraining's auc: 0.991928\tvalid_1's auc: 0.918664\n",
      "[220]\ttraining's auc: 0.992583\tvalid_1's auc: 0.918744\n",
      "[230]\ttraining's auc: 0.993168\tvalid_1's auc: 0.918856\n",
      "[240]\ttraining's auc: 0.993642\tvalid_1's auc: 0.91911\n",
      "[250]\ttraining's auc: 0.994209\tvalid_1's auc: 0.919121\n",
      "[260]\ttraining's auc: 0.994636\tvalid_1's auc: 0.919379\n",
      "[270]\ttraining's auc: 0.995005\tvalid_1's auc: 0.919572\n",
      "[280]\ttraining's auc: 0.995377\tvalid_1's auc: 0.91965\n",
      "[290]\ttraining's auc: 0.995733\tvalid_1's auc: 0.919646\n",
      "[300]\ttraining's auc: 0.996023\tvalid_1's auc: 0.91967\n",
      "[310]\ttraining's auc: 0.996335\tvalid_1's auc: 0.919781\n",
      "[320]\ttraining's auc: 0.996595\tvalid_1's auc: 0.919894\n",
      "[330]\ttraining's auc: 0.996836\tvalid_1's auc: 0.919791\n",
      "[340]\ttraining's auc: 0.997075\tvalid_1's auc: 0.919767\n",
      "[350]\ttraining's auc: 0.997297\tvalid_1's auc: 0.919674\n",
      "[360]\ttraining's auc: 0.997502\tvalid_1's auc: 0.919753\n",
      "[370]\ttraining's auc: 0.997686\tvalid_1's auc: 0.919675\n",
      "[380]\ttraining's auc: 0.997882\tvalid_1's auc: 0.919761\n",
      "[390]\ttraining's auc: 0.998044\tvalid_1's auc: 0.919591\n",
      "[400]\ttraining's auc: 0.99819\tvalid_1's auc: 0.919531\n",
      "[410]\ttraining's auc: 0.99834\tvalid_1's auc: 0.919389\n",
      "Early stopping, best iteration is:\n",
      "[315]\ttraining's auc: 0.996469\tvalid_1's auc: 0.919979\n",
      "Fold 3 | AUC: 0.9199740906128382\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.946214\tvalid_1's auc: 0.915249\n",
      "[20]\ttraining's auc: 0.957376\tvalid_1's auc: 0.919007\n",
      "[30]\ttraining's auc: 0.962926\tvalid_1's auc: 0.921449\n",
      "[40]\ttraining's auc: 0.966317\tvalid_1's auc: 0.922771\n",
      "[50]\ttraining's auc: 0.96913\tvalid_1's auc: 0.924216\n",
      "[60]\ttraining's auc: 0.971549\tvalid_1's auc: 0.925594\n",
      "[70]\ttraining's auc: 0.97436\tvalid_1's auc: 0.927414\n",
      "[80]\ttraining's auc: 0.977091\tvalid_1's auc: 0.928611\n",
      "[90]\ttraining's auc: 0.979118\tvalid_1's auc: 0.929587\n",
      "[100]\ttraining's auc: 0.980938\tvalid_1's auc: 0.930351\n",
      "[110]\ttraining's auc: 0.9828\tvalid_1's auc: 0.931332\n",
      "[120]\ttraining's auc: 0.984178\tvalid_1's auc: 0.932096\n",
      "[130]\ttraining's auc: 0.985408\tvalid_1's auc: 0.933059\n",
      "[140]\ttraining's auc: 0.98653\tvalid_1's auc: 0.933661\n",
      "[150]\ttraining's auc: 0.987545\tvalid_1's auc: 0.934238\n",
      "[160]\ttraining's auc: 0.98845\tvalid_1's auc: 0.934664\n",
      "[170]\ttraining's auc: 0.989328\tvalid_1's auc: 0.935061\n",
      "[180]\ttraining's auc: 0.990129\tvalid_1's auc: 0.935493\n",
      "[190]\ttraining's auc: 0.990902\tvalid_1's auc: 0.935895\n",
      "[200]\ttraining's auc: 0.991555\tvalid_1's auc: 0.936323\n",
      "[210]\ttraining's auc: 0.992222\tvalid_1's auc: 0.936563\n",
      "[220]\ttraining's auc: 0.992771\tvalid_1's auc: 0.936697\n",
      "[230]\ttraining's auc: 0.99337\tvalid_1's auc: 0.936838\n",
      "[240]\ttraining's auc: 0.993818\tvalid_1's auc: 0.937097\n",
      "[250]\ttraining's auc: 0.994294\tvalid_1's auc: 0.937189\n",
      "[260]\ttraining's auc: 0.994773\tvalid_1's auc: 0.937289\n",
      "[270]\ttraining's auc: 0.99516\tvalid_1's auc: 0.937573\n",
      "[280]\ttraining's auc: 0.99554\tvalid_1's auc: 0.937714\n",
      "[290]\ttraining's auc: 0.995901\tvalid_1's auc: 0.937608\n",
      "[300]\ttraining's auc: 0.996222\tvalid_1's auc: 0.937623\n",
      "[310]\ttraining's auc: 0.996491\tvalid_1's auc: 0.937687\n",
      "[320]\ttraining's auc: 0.996749\tvalid_1's auc: 0.93777\n",
      "[330]\ttraining's auc: 0.996993\tvalid_1's auc: 0.937702\n",
      "[340]\ttraining's auc: 0.997207\tvalid_1's auc: 0.937662\n",
      "[350]\ttraining's auc: 0.997424\tvalid_1's auc: 0.93765\n",
      "[360]\ttraining's auc: 0.997623\tvalid_1's auc: 0.937698\n",
      "[370]\ttraining's auc: 0.99782\tvalid_1's auc: 0.937546\n",
      "[380]\ttraining's auc: 0.99799\tvalid_1's auc: 0.93736\n",
      "[390]\ttraining's auc: 0.998144\tvalid_1's auc: 0.93721\n",
      "[400]\ttraining's auc: 0.998285\tvalid_1's auc: 0.937073\n",
      "[410]\ttraining's auc: 0.998405\tvalid_1's auc: 0.93681\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttraining's auc: 0.996653\tvalid_1's auc: 0.937812\n",
      "Fold 4 | AUC: 0.9378078406565793\n",
      "Fold: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.94618\tvalid_1's auc: 0.883472\n",
      "[20]\ttraining's auc: 0.958275\tvalid_1's auc: 0.894924\n",
      "[30]\ttraining's auc: 0.964567\tvalid_1's auc: 0.898893\n",
      "[40]\ttraining's auc: 0.968085\tvalid_1's auc: 0.900679\n",
      "[50]\ttraining's auc: 0.970824\tvalid_1's auc: 0.901621\n",
      "[60]\ttraining's auc: 0.972826\tvalid_1's auc: 0.902913\n",
      "[70]\ttraining's auc: 0.975355\tvalid_1's auc: 0.904127\n",
      "[80]\ttraining's auc: 0.977527\tvalid_1's auc: 0.904762\n",
      "[90]\ttraining's auc: 0.979338\tvalid_1's auc: 0.905418\n",
      "[100]\ttraining's auc: 0.980867\tvalid_1's auc: 0.90581\n",
      "[110]\ttraining's auc: 0.982436\tvalid_1's auc: 0.906253\n",
      "[120]\ttraining's auc: 0.98359\tvalid_1's auc: 0.906673\n",
      "[130]\ttraining's auc: 0.984644\tvalid_1's auc: 0.907275\n",
      "[140]\ttraining's auc: 0.985592\tvalid_1's auc: 0.907646\n",
      "[150]\ttraining's auc: 0.986634\tvalid_1's auc: 0.907762\n",
      "[160]\ttraining's auc: 0.98752\tvalid_1's auc: 0.908003\n",
      "[170]\ttraining's auc: 0.988408\tvalid_1's auc: 0.908051\n",
      "[180]\ttraining's auc: 0.989387\tvalid_1's auc: 0.908182\n",
      "[190]\ttraining's auc: 0.99026\tvalid_1's auc: 0.90843\n",
      "[200]\ttraining's auc: 0.990908\tvalid_1's auc: 0.908868\n",
      "[210]\ttraining's auc: 0.991609\tvalid_1's auc: 0.908731\n",
      "[220]\ttraining's auc: 0.992223\tvalid_1's auc: 0.908995\n",
      "[230]\ttraining's auc: 0.992787\tvalid_1's auc: 0.909197\n",
      "[240]\ttraining's auc: 0.993326\tvalid_1's auc: 0.909493\n",
      "[250]\ttraining's auc: 0.993924\tvalid_1's auc: 0.909809\n",
      "[260]\ttraining's auc: 0.994408\tvalid_1's auc: 0.910085\n",
      "[270]\ttraining's auc: 0.99479\tvalid_1's auc: 0.910365\n",
      "[280]\ttraining's auc: 0.995188\tvalid_1's auc: 0.910498\n",
      "[290]\ttraining's auc: 0.995555\tvalid_1's auc: 0.910451\n",
      "[300]\ttraining's auc: 0.995847\tvalid_1's auc: 0.910616\n",
      "[310]\ttraining's auc: 0.996134\tvalid_1's auc: 0.911093\n",
      "[320]\ttraining's auc: 0.996385\tvalid_1's auc: 0.911097\n",
      "[330]\ttraining's auc: 0.996659\tvalid_1's auc: 0.910818\n",
      "[340]\ttraining's auc: 0.996912\tvalid_1's auc: 0.910916\n",
      "[350]\ttraining's auc: 0.997139\tvalid_1's auc: 0.910852\n",
      "[360]\ttraining's auc: 0.997337\tvalid_1's auc: 0.910877\n",
      "[370]\ttraining's auc: 0.99754\tvalid_1's auc: 0.910916\n",
      "[380]\ttraining's auc: 0.997731\tvalid_1's auc: 0.91092\n",
      "[390]\ttraining's auc: 0.997925\tvalid_1's auc: 0.910873\n",
      "[400]\ttraining's auc: 0.998082\tvalid_1's auc: 0.910832\n",
      "[410]\ttraining's auc: 0.998217\tvalid_1's auc: 0.911045\n",
      "Early stopping, best iteration is:\n",
      "[315]\ttraining's auc: 0.996272\tvalid_1's auc: 0.911129\n",
      "Fold 5 | AUC: 0.9111275703057833\n",
      "\n",
      "Mean AUC = 0.9208513987155897\n",
      "Out of folds AUC = 0.9056733029100525\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 5\n",
    "SEED = 6\n",
    "\n",
    "columns = X_train.columns\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = columns\n",
    "\n",
    "folds = KFold(n_splits=N_SPLITS, random_state=SEED)\n",
    "# Test Data and expport DF\n",
    "  \n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "\n",
    "score = 0\n",
    "y_result = 0\n",
    "print(\"running\")\n",
    "# use stratified fold to ensure the split datasets have same portion of postive and negative data.\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print('Fold:',fold_+1)\n",
    "    tr_x, tr_y = X_train.iloc[trn_idx,:], y_train.iloc[trn_idx]    \n",
    "    vl_x, v_y = X_train.iloc[val_idx,:], y_train.iloc[val_idx]    \n",
    "    train_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    valid_data = lgb.Dataset(vl_x, label=v_y)  \n",
    "        \n",
    "    #this will run very slow. \n",
    "    num_round =5000\n",
    "        \n",
    "    #here valid sets are the criteria for stopping, when the auc score for valid sets do not improve after num_round, then it will stop. \n",
    "    estimator = lgb.train(\n",
    "            best_param,\n",
    "            train_data, \n",
    "            num_round,\n",
    "            valid_sets = [train_data,valid_data],\n",
    "            #print evaluation at each step\n",
    "            verbose_eval = 10,\n",
    "            )\n",
    "\n",
    "    y_pred_valid = estimator.predict(vl_x)\n",
    "    y_oof[val_idx] = y_pred_valid\n",
    "    print(f\"Fold {fold_ + 1} | AUC: {roc_auc_score(v_y, y_pred_valid)}\")\n",
    "    \n",
    "    #score is the roc_auc of valid pred \n",
    "    score += roc_auc_score(v_y, y_pred_valid) / N_SPLITS\n",
    "    y_result += estimator.predict(X_test) / N_SPLITS\n",
    "    # we are not sure what fold is best for us\n",
    "    # so we will average prediction results \n",
    "    # over folds; meaning each fold we predict test data and then get average.\n",
    "    \n",
    "    feature_importances[f'fold_{fold_ + 1}'] = estimator.feature_importance()\n",
    "\n",
    "    del train_data, valid_data\n",
    "    gc.collect()\n",
    "print(f\"\\nMean AUC = {score}\")\n",
    "print(f\"Out of folds AUC = {roc_auc_score(y_train, y_oof)}\")\n",
    "    #print('LOG loss', metrics.log_loss(RESULTS['isFraud'], RESULTS['stratifiedkfold']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##trick here \n",
    "##for oof = 0.93547, LB score is 0.9458\n",
    "##for oof = 0.936, LB score is 0.945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "##take the mean of each feature importance of all folds. \n",
    "feature_importances['average'] = feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(folds.n_splits)]].mean(axis=1)\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "sns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\n",
    "plt.title('50 TOP feature importance over {} folds average'.format(folds.n_splits));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19908"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub = pd.DataFrame(columns=['TransactionID','isFraud'])\n",
    "sub['TransactionID'] = X_test.index\n",
    "sub['isFraud'] = y_result\n",
    "sub\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sub.to_csv(\"submission58th-updated-03.csv\",index=False)\n",
    "\n",
    "sum(y_result>0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_result>0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
